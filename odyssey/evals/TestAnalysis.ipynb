{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "\n",
    "ROOT = \"/fs01/home/afallah/odyssey/odyssey\"\n",
    "os.chdir(ROOT)\n",
    "\n",
    "from odyssey.data.dataset import FinetuneMultiDataset, FinetuneDatasetDecoder\n",
    "from odyssey.data.tokenizer import ConceptTokenizer\n",
    "from odyssey.models.model_utils import load_finetune_data, load_pretrain_data\n",
    "from odyssey.evals.evaluation import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    \"\"\"Save the configuration arguments.\"\"\"\n",
    "\n",
    "    # test_outputs = \"checkpoints/mamba_finetune_with_embeddings/test_outputs/test_outputs_f521131a.pt\"   # original\n",
    "    # test_outputs = \"checkpoints/mamba_finetune_with_embeddings/test_outputs/test_outputs_dd3a541e.pt\"   # original 2\n",
    "    # test_outputs = \"checkpoints/mamba_finetune_with_embeddings/test_outputs/test_outputs_8d4a82a7.pt\"   # Mamba new 3\n",
    "    # test_outputs = \"checkpoints/mamba_finetune_with_embeddings/test_outputs/test_outputs_cc5497f1.pt\"   # Mamba new 5\n",
    "    # test_outputs = \"checkpoints/mamba_finetune_with_embeddings/test_outputs/test_outputs_189dcaa6.pt\"   # Mamba new 4\n",
    "    # test_outputs = \"checkpoints/mamba_finetune_with_embeddings/test_outputs/test_outputs_f65e9b55.pt\"   # Mamba new 6\n",
    "    # test_outputs = \"checkpoints/multibird_finetune/test_outputs/test_outputs_e112ebb5.pt\"               # Multibird 4\n",
    "    # test_outputs = \"checkpoints/multibird_finetune/test_outputs/test_outputs_782a830c.pt\"                # Multibird 5\n",
    "    # test_outputs = \"checkpoints/multibird_finetune/test_outputs/test_outputs_849dfdc5.pt\" # Multibird 7\n",
    "    test_outputs = \"checkpoints/multibird_finetune/test_outputs/test_outputs_102b8d16.pt\"  # Multibird 8\n",
    "    # test_outputs = \"checkpoints/mamba_finetune_with_embeddings_multihead/test_outputs/test_outputs_d3d3deb6.pt\" # Multihead 6\n",
    "    # test_outputs = \"checkpoints/mamba_finetune_with_embeddings_multihead/test_outputs/test_outputs_543b92de.pt\" # Multihead 4\n",
    "    # test_outputs = \"checkpoints/mamba_finetune_with_embeddings_multihead/test_outputs/test_outputs_65922b58.pt\" # Multihead 3\n",
    "    # test_outputs = \"/ssd003/projects/aieng/public/odyssey/checkpoints/multibird_finetune/v1/test_outputs/test_outputs_1ec842db.pt\"\n",
    "    vocab_dir = \"odyssey/data/vocab\"\n",
    "    data_dir = \"odyssey/data/bigbird_data\"\n",
    "    sequence_file = \"patient_sequences_2048_multi_v2.parquet\"\n",
    "    id_file = \"dataset_2048_multi_v2.pkl\"\n",
    "    valid_scheme = \"few_shot\"\n",
    "    num_finetune_patients = \"all\"\n",
    "    # label_name = \"label_mortality_1month\"\n",
    "    tasks = [\n",
    "        \"mortality_1month\",\n",
    "        \"readmission_1month\",\n",
    "        \"los_1week\",\n",
    "        \"c0\",\n",
    "        \"c1\",\n",
    "        \"c2\",\n",
    "    ]  # CHANGE LATER!!!! 'readmission_1month',\n",
    "\n",
    "    max_len = 2048\n",
    "    batch_size = 1\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = ConceptTokenizer(data_dir=config.vocab_dir)\n",
    "tokenizer.fit_on_vocab()\n",
    "\n",
    "# Load pretrain data\n",
    "# pretrain = load_pretrain_data(\n",
    "#     config.data_dir,\n",
    "#     'patient_sequences/'+config.sequence_file,\n",
    "#     'patient_id_dict/'+config.id_file,\n",
    "# )\n",
    "\n",
    "# Load test data\n",
    "fine_tune, fine_test = load_finetune_data(\n",
    "    config.data_dir,\n",
    "    config.sequence_file,\n",
    "    config.id_file,\n",
    "    config.valid_scheme,\n",
    "    config.num_finetune_patients,\n",
    ")\n",
    "\n",
    "# test_dataset = FinetuneDatasetDecoder(\n",
    "#     data=fine_test,\n",
    "#     tokenizer=tokenizer,\n",
    "#     tasks=config.tasks,\n",
    "#     balance_guide=None,\n",
    "#     max_len=config.max_len,\n",
    "# )\n",
    "\n",
    "test_dataset = FinetuneMultiDataset(\n",
    "    data=fine_test,\n",
    "    tokenizer=tokenizer,\n",
    "    tasks=config.tasks,\n",
    "    balance_guide=None,\n",
    "    max_len=config.max_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31775, 122109, 20851581, 0.4911723052714398)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label = 'label_readmission_1month'\n",
    "\n",
    "# (len(fine_tune.loc[fine_tune[label] != -1]),\n",
    "#  fine_tune.loc[fine_tune[label] != -1]['num_visits'].sum(),\n",
    "# fine_tune.loc[fine_tune[label] != -1]['event_tokens_2048'].transform(len).sum(),\n",
    "# fine_tune.loc[fine_tune[label] != -1][label].mean())\n",
    "\n",
    "# (len(fine_test.loc[fine_test[label] != -1]),\n",
    "# fine_test.loc[fine_test[label] != -1]['num_visits'].sum(),\n",
    "# fine_test.loc[fine_test[label] != -1]['event_tokens_2048'].transform(len).sum(),\n",
    "# fine_test.loc[fine_test[label] != -1][label].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [test_dataset.index_mapper[i][1] for i in range(len(test_dataset))]\n",
    "task2index = {task: [] for task in config.tasks}\n",
    "for i, task in enumerate(tasks):\n",
    "    task2index[task].append(i)\n",
    "\n",
    "\n",
    "def test_model():\n",
    "    test_outputs = torch.load(config.test_outputs, map_location=config.device)\n",
    "    test_outputs.keys()\n",
    "\n",
    "    labels = test_outputs[\"labels\"].cpu().numpy()\n",
    "    logits = test_outputs[\"logits\"].cpu().numpy()\n",
    "    probs = torch.sigmoid(torch.tensor(logits[:, 1])).cpu().numpy()\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    for task, task_idx in task2index.items():\n",
    "        print(f\"Task: {task}\")\n",
    "        print(calculate_metrics(labels[task_idx], preds[task_idx], probs[task_idx]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.8655722026231953, 'F1 Score': 0.7755274261603375, 'Precision': 0.8012205754141238, 'Recall': 0.7514309076042518, 'AUROC': 0.9689994603245022, 'Average Precision Score': 0.6264560624156887, 'AUC-PR': 0.8643278717781356}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.624845239226117, 'F1 Score': 0.5496580918267665, 'Precision': 0.5174739423666462, 'Recall': 0.5861111111111111, 'AUROC': 0.6787862460815047, 'Average Precision Score': 0.4609969980142222, 'AUC-PR': 0.5676588678703538}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.7985457953399953, 'F1 Score': 0.7134502923976608, 'Precision': 0.6906662795761359, 'Recall': 0.7377888044658086, 'AUROC': 0.8908909347887108, 'Average Precision Score': 0.5878710119255549, 'AUC-PR': 0.8054669969100448}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.7566179832371729, 'F1 Score': 0.7189705670523839, 'Precision': 0.7488497699539908, 'Recall': 0.6913842460060947, 'AUROC': 0.8520657893413595, 'Average Precision Score': 0.6518305599556854, 'AUC-PR': 0.7998110484365605}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.7902834108282778, 'F1 Score': 0.7204893707225486, 'Precision': 0.7242177036405698, 'Recall': 0.7167992287298144, 'AUROC': 0.8808745363270618, 'Average Precision Score': 0.61340532276137, 'AUC-PR': 0.803309787337278}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.8061079075532775, 'F1 Score': 0.697747676799496, 'Precision': 0.6697913516782582, 'Recall': 0.7281393819855358, 'AUROC': 0.9091717328595696, 'Average Precision Score': 0.5540632005589171, 'AUC-PR': 0.7476423343654992}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model()  # Multihead 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.8780054916237896, 'F1 Score': 0.7883060335890525, 'Precision': 0.7997475809844342, 'Recall': 0.7771872444807849, 'AUROC': 0.9726084128993358, 'Average Precision Score': 0.6434200928266727, 'AUC-PR': 0.8776861929897538}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.6276137155251575, 'F1 Score': 0.5369158878504673, 'Precision': 0.5419811320754717, 'Recall': 0.5319444444444444, 'AUROC': 0.6863716679596382, 'Average Precision Score': 0.4666421834766151, 'AUC-PR': 0.5772680378049946}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.8087185027022964, 'F1 Score': 0.7203293583191368, 'Precision': 0.664223065846315, 'Recall': 0.7867886494030082, 'AUROC': 0.8948934510936986, 'Average Precision Score': 0.5862753152097165, 'AUC-PR': 0.8089246395692433}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.7832233228926138, 'F1 Score': 0.7517542196093305, 'Precision': 0.7724836792360908, 'Recall': 0.7321082279065473, 'AUROC': 0.8719728806194893, 'Average Precision Score': 0.6819354947575507, 'AUC-PR': 0.8318177676555147}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.7797870622105356, 'F1 Score': 0.7099749637633417, 'Precision': 0.7831395348837209, 'Recall': 0.6493130874909617, 'AUROC': 0.8867744454821174, 'Average Precision Score': 0.6252576843339919, 'AUC-PR': 0.8117944395395661}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.8250345481727157, 'F1 Score': 0.7356302935613848, 'Precision': 0.7360539740003291, 'Recall': 0.735207100591716, 'AUROC': 0.9237722006906843, 'Average Precision Score': 0.605788603048424, 'AUC-PR': 0.7914686459835204}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model()  # Multihead 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.9046091364922854, 'F1 Score': 0.6942788074133763, 'Precision': 0.573024740622506, 'Recall': 0.8806214227309894, 'AUROC': 0.9721118612424308, 'Average Precision Score': 0.5163334778180794, 'AUC-PR': 0.8741390162810497}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.6447714796662094, 'F1 Score': 0.572943722943723, 'Precision': 0.5363728470111448, 'Recall': 0.6148664343786295, 'AUROC': 0.6995091168843479, 'Average Precision Score': 0.476031563625974, 'AUC-PR': 0.5895119974155991}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.8228229864371363, 'F1 Score': 0.7352697095435685, 'Precision': 0.6644169478815148, 'Recall': 0.8230376219228983, 'AUROC': 0.9082735533076256, 'Average Precision Score': 0.59976906348086, 'AUC-PR': 0.8323074699576767}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.8014407368019587, 'F1 Score': 0.7808064094748759, 'Precision': 0.7390372568414112, 'Recall': 0.8275798412405391, 'AUROC': 0.8875025728612694, 'Average Precision Score': 0.68656017712563, 'AUC-PR': 0.853880700811249}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.8027235478428537, 'F1 Score': 0.7332341496910048, 'Precision': 0.6980823708869035, 'Recall': 0.7721137623523741, 'AUROC': 0.890846014238589, 'Average Precision Score': 0.6148696525835217, 'AUC-PR': 0.8144010739146099}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.8357298772597646, 'F1 Score': 0.6896681749622926, 'Precision': 0.5583028083028083, 'Recall': 0.9018737672583826, 'AUROC': 0.913702991801963, 'Average Precision Score': 0.5274714735573378, 'AUC-PR': 0.7505209492801801}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model()  # Original 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.9046091364922854, 'F1 Score': 0.6942788074133763, 'Precision': 0.573024740622506, 'Recall': 0.8806214227309894, 'AUROC': 0.9721118612424308, 'Average Precision Score': 0.5163334778180794, 'AUC-PR': 0.7326808894122636}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.6447714796662094, 'F1 Score': 0.572943722943723, 'Precision': 0.5363728470111448, 'Recall': 0.6148664343786295, 'AUROC': 0.6995091168843479, 'Average Precision Score': 0.476031563625974, 'AUC-PR': 0.6487365925382458}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.8228229864371363, 'F1 Score': 0.7352697095435685, 'Precision': 0.6644169478815148, 'Recall': 0.8230376219228983, 'AUROC': 0.9082735533076256, 'Average Precision Score': 0.59976906348086, 'AUC-PR': 0.7701917442678005}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.8014407368019587, 'F1 Score': 0.7808064094748759, 'Precision': 0.7390372568414112, 'Recall': 0.8275798412405391, 'AUROC': 0.8875025728612694, 'Average Precision Score': 0.68656017712563, 'AUC-PR': 0.8207824697599608}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.8027235478428537, 'F1 Score': 0.7332341496910048, 'Precision': 0.6980823708869035, 'Recall': 0.7721137623523741, 'AUROC': 0.890846014238589, 'Average Precision Score': 0.6148696525835217, 'AUC-PR': 0.7730333900027234}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.8357298772597646, 'F1 Score': 0.6896681749622926, 'Precision': 0.5583028083028083, 'Recall': 0.9018737672583826, 'AUROC': 0.913702991801963, 'Average Precision Score': 0.5274714735573378, 'AUC-PR': 0.7420646960617703}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.9031064952616157, 'F1 Score': 0.7067020570670206, 'Precision': 0.5946398659966499, 'Recall': 0.8708094848732625, 'AUROC': 0.972161114452456, 'Average Precision Score': 0.5304965781636694, 'AUC-PR': 0.8680130845060448}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.617183815538263, 'F1 Score': 0.4710590252965557, 'Precision': 0.612184249628529, 'Recall': 0.3828106852497096, 'AUROC': 0.6963517269590036, 'Average Precision Score': 0.4686953537010699, 'AUC-PR': 0.583781093737475}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.8264205588789526, 'F1 Score': 0.737919737919738, 'Precision': 0.6598315635298425, 'Recall': 0.8369716674407803, 'AUROC': 0.9093339907980309, 'Average Precision Score': 0.6010216112926607, 'AUC-PR': 0.831706725413936}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.7992014533014051, 'F1 Score': 0.7732314631564413, 'Precision': 0.7711374277058661, 'Recall': 0.7753369023444711, 'AUROC': 0.8856379346465069, 'Average Precision Score': 0.6955481813851433, 'AUC-PR': 0.8517375666790431}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.8069692653110465, 'F1 Score': 0.7352844818171891, 'Precision': 0.6722244408945687, 'Recall': 0.8114003374307062, 'AUROC': 0.8905309758413567, 'Average Precision Score': 0.6082340224592571, 'AUC-PR': 0.8155456365782184}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.830794356713024, 'F1 Score': 0.7471321695760599, 'Precision': 0.7558022199798183, 'Recall': 0.7386587771203156, 'AUROC': 0.9297505656827068, 'Average Precision Score': 0.6220738771131287, 'AUC-PR': 0.8059679193237211}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model()  # New 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.8622720192950359, 'F1 Score': 0.7799742157284056, 'Precision': 0.8220108695652174, 'Recall': 0.7420278004905969, 'AUROC': 0.9702276440443593, 'Average Precision Score': 0.6352718810920918, 'AUC-PR': 0.8674110558595907}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.6262484101727832, 'F1 Score': 0.5413209048539275, 'Precision': 0.5318293500111682, 'Recall': 0.5511574074074074, 'AUROC': 0.68287825353852, 'Average Precision Score': 0.4641395019286542, 'AUC-PR': 0.5680185975838656}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.799364691960775, 'F1 Score': 0.7138704628456436, 'Precision': 0.687284730195178, 'Recall': 0.7425957512792681, 'AUROC': 0.8938146814638854, 'Average Precision Score': 0.5872443663133886, 'AUC-PR': 0.808685370471159}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.7842020547679327, 'F1 Score': 0.7565109549400578, 'Precision': 0.7526046426613051, 'Recall': 0.7604580293655924, 'AUROC': 0.871564490669245, 'Average Precision Score': 0.6764006356819985, 'AUC-PR': 0.8290430984819187}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.769950523094137, 'F1 Score': 0.6967953985209532, 'Precision': 0.8068506184586108, 'Recall': 0.6131597975415762, 'AUROC': 0.8859534364355173, 'Average Precision Score': 0.6235198881001462, 'AUC-PR': 0.8128432000074219}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.8182716910178939, 'F1 Score': 0.7294471857489336, 'Precision': 0.7425506555423123, 'Recall': 0.7167981591058514, 'AUROC': 0.9214275139204708, 'Average Precision Score': 0.6013890986088193, 'AUC-PR': 0.7851452042998618}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model()  # New 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.8753458000943887, 'F1 Score': 0.7728013029315961, 'Precision': 0.7696674776966748, 'Recall': 0.7759607522485691, 'AUROC': 0.9705738897457072, 'Average Precision Score': 0.6192185949683511, 'AUC-PR': 0.8678600307736943}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.6246481600223763, 'F1 Score': 0.5342481683916734, 'Precision': 0.5368076653423697, 'Recall': 0.531712962962963, 'AUROC': 0.680164563608921, 'Average Precision Score': 0.4638541245326711, 'AUC-PR': 0.5693479032442244}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.7979240340522251, 'F1 Score': 0.7127627627627627, 'Precision': 0.6908746907291515, 'Recall': 0.7360831136610327, 'AUROC': 0.8915162383799904, 'Average Precision Score': 0.587355733904388, 'AUC-PR': 0.804778620144726}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.7675343469447702, 'F1 Score': 0.7329269454233737, 'Precision': 0.7567115743927623, 'Recall': 0.710591929079324, 'AUROC': 0.8575170903900623, 'Average Precision Score': 0.6634553938640426, 'AUC-PR': 0.8041353945716925}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.7669696706384402, 'F1 Score': 0.6922760887428102, 'Precision': 0.801617507136061, 'Recall': 0.6091829356471439, 'AUROC': 0.8844497674832738, 'Average Precision Score': 0.6184472575391696, 'AUC-PR': 0.8091890280184044}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.8108473933927143, 'F1 Score': 0.7095111540629782, 'Precision': 0.6955629243644402, 'Recall': 0.7240302432610125, 'AUROC': 0.9148729796298392, 'Average Precision Score': 0.5709733822893606, 'AUC-PR': 0.7622973843101764}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model()  # New 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.8690388246976402, 'F1 Score': 0.7823516993877981, 'Precision': 0.8088171104321257, 'Recall': 0.7575633687653311, 'AUROC': 0.9719834173099352, 'Average Precision Score': 0.6365225435731867, 'AUC-PR': 0.8732467381784418}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.6299158315126183, 'F1 Score': 0.5478495834271561, 'Precision': 0.5333187198597107, 'Recall': 0.5631944444444444, 'AUROC': 0.6873234698077959, 'Average Precision Score': 0.46679360953816706, 'AUC-PR': 0.5735717003134541}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.8025800848789157, 'F1 Score': 0.7169839161871034, 'Precision': 0.6838845883180859, 'Recall': 0.7534501473096604, 'AUROC': 0.8937000531366002, 'Average Precision Score': 0.5889010984765001, 'AUC-PR': 0.8078436780997615}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.7889936829917931, 'F1 Score': 0.7573392078923423, 'Precision': 0.7866096299243932, 'Recall': 0.7301689906731924, 'AUROC': 0.8796977562547927, 'Average Precision Score': 0.6915943581876093, 'AUC-PR': 0.8450574140346002}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.7795420174466479, 'F1 Score': 0.7099515368784439, 'Precision': 0.7903917220990392, 'Recall': 0.6443721378645457, 'AUROC': 0.8873725824489701, 'Average Precision Score': 0.6277063395242446, 'AUC-PR': 0.8143638357999128}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.8211258935413761, 'F1 Score': 0.7347041544271926, 'Precision': 0.7506431143886126, 'Recall': 0.7194280078895463, 'AUROC': 0.9244992477920578, 'Average Precision Score': 0.6085218845611918, 'AUC-PR': 0.7940380044618962}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model()  # New 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.878934427535469, 'F1 Score': 0.7252909661924996, 'Precision': 0.6616110549376475, 'Recall': 0.8025347506132461, 'AUROC': 0.9646008285597611, 'Average Precision Score': 0.5503447748695037, 'AUC-PR': 0.8353257173010042}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.7773360432023431, 'F1 Score': 0.6808632680863268, 'Precision': 0.6332355294745265, 'Recall': 0.7362381764614669, 'AUROC': 0.8699980601281244, 'Average Precision Score': 0.5449804048782951, 'AUC-PR': 0.7670872175086823}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.6258331420263239, 'F1 Score': 0.5516272029408584, 'Precision': 0.5175491986204098, 'Recall': 0.5905092592592592, 'AUROC': 0.679461807204754, 'Average Precision Score': 0.461641584029276, 'AUC-PR': 0.5637195916045253}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.7902966398445754, 'F1 Score': 0.7589046342397548, 'Precision': 0.7879510885773934, 'Recall': 0.7319235386462277, 'AUROC': 0.8802952315807759, 'Average Precision Score': 0.6931940302385818, 'AUC-PR': 0.8482679133653025}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.7845867126200077, 'F1 Score': 0.7133243606998654, 'Precision': 0.7244035785288271, 'Recall': 0.7025789346830562, 'AUROC': 0.8765327601806833, 'Average Precision Score': 0.6079717183960716, 'AUC-PR': 0.798202291297643}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.836848243487146, 'F1 Score': 0.7483870967741936, 'Precision': 0.7346421785940469, 'Recall': 0.7626561472715319, 'AUROC': 0.9276539976074517, 'Average Precision Score': 0.6182154993722009, 'AUC-PR': 0.7986724357622783}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model()  # Multibird 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.8307360510289447, 'F1 Score': 0.7477946166025786, 'Precision': 0.8369620253164557, 'Recall': 0.6757972199509403, 'AUROC': 0.9617723793090831, 'Average Precision Score': 0.597433332750795, 'AUC-PR': 0.8299543351752259}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.6081461823037059, 'F1 Score': 0.47329276538201487, 'Precision': 0.5691056910569106, 'Recall': 0.4050925925925926, 'AUROC': 0.6729919360797103, 'Average Precision Score': 0.4572118704615439, 'AUC-PR': 0.5584318732316119}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.7567032514271541, 'F1 Score': 0.6653495962892974, 'Precision': 0.7458116695551704, 'Recall': 0.6005582260815631, 'AUROC': 0.8733449329098977, 'Average Precision Score': 0.5671902052200841, 'AUC-PR': 0.772768315710113}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.7907783355108081, 'F1 Score': 0.7676427590484207, 'Precision': 0.7377384196185286, 'Recall': 0.8000738757041278, 'AUROC': 0.878586426793819, 'Average Precision Score': 0.6771093034029938, 'AUC-PR': 0.8452584181101737}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.7549182478131674, 'F1 Score': 0.6741229593608892, 'Precision': 0.7958012137116615, 'Recall': 0.5847192094480598, 'AUROC': 0.8776506070328594, 'Average Precision Score': 0.6035805679057825, 'AUC-PR': 0.7978530779644457}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.8147672500073284, 'F1 Score': 0.7326629680998613, 'Precision': 0.7751283932501835, 'Recall': 0.6946088099934253, 'AUROC': 0.9262240173313177, 'Average Precision Score': 0.6129576325576852, 'AUC-PR': 0.7958061545635383}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model()  # Multibird 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.8715696903457233, 'F1 Score': 0.7514382067050188, 'Precision': 0.7298651252408478, 'Recall': 0.7743254292722813, 'AUROC': 0.9675795019198202, 'Average Precision Score': 0.5873004542897322, 'AUC-PR': 0.8468842847116425}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.6297042063793631, 'F1 Score': 0.5435356200527705, 'Precision': 0.5387764384807824, 'Recall': 0.5483796296296296, 'AUROC': 0.6840408229367869, 'Average Precision Score': 0.467530227703297, 'AUC-PR': 0.5705826681588523}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.781210473498072, 'F1 Score': 0.6900330231161813, 'Precision': 0.6686545454545455, 'Recall': 0.7128236935959064, 'AUROC': 0.8750743499816753, 'Average Precision Score': 0.5623933955603996, 'AUC-PR': 0.7840703889371606}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.7974596742399855, 'F1 Score': 0.7718961418906565, 'Precision': 0.7642798949941161, 'Recall': 0.7796657124388217, 'AUROC': 0.8842594008160198, 'Average Precision Score': 0.691613851141071, 'AUC-PR': 0.8533024917017453}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.7804055996414331, 'F1 Score': 0.7095783479429266, 'Precision': 0.7563770290546992, 'Recall': 0.66823330923114, 'AUROC': 0.881878395722294, 'Average Precision Score': 0.6158921107398279, 'AUC-PR': 0.8041114582693347}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.8232807049502298, 'F1 Score': 0.7395710184090525, 'Precision': 0.7605071205279611, 'Recall': 0.7197567389875082, 'AUROC': 0.9272017742406032, 'Average Precision Score': 0.6157880852469901, 'AUC-PR': 0.8024466005615527}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model()  # Multibird 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.8715696903457233, 'F1 Score': 0.7514382067050188, 'Precision': 0.7298651252408478, 'Recall': 0.7743254292722813, 'AUROC': 0.9675795019198202, 'Average Precision Score': 0.5873004542897322, 'AUC-PR': 0.8468842847116425}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.6297042063793631, 'F1 Score': 0.5435356200527705, 'Precision': 0.5387764384807824, 'Recall': 0.5483796296296296, 'AUROC': 0.6840408229367869, 'Average Precision Score': 0.467530227703297, 'AUC-PR': 0.5705826681588523}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.781210473498072, 'F1 Score': 0.6900330231161813, 'Precision': 0.6686545454545455, 'Recall': 0.7128236935959064, 'AUROC': 0.8750743499816753, 'Average Precision Score': 0.5623933955603996, 'AUC-PR': 0.7840703889371606}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.7974596742399855, 'F1 Score': 0.7718961418906565, 'Precision': 0.7642798949941161, 'Recall': 0.7796657124388217, 'AUROC': 0.8842594008160198, 'Average Precision Score': 0.691613851141071, 'AUC-PR': 0.8533024917017453}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.7804055996414331, 'F1 Score': 0.7095783479429266, 'Precision': 0.7563770290546992, 'Recall': 0.66823330923114, 'AUROC': 0.881878395722294, 'Average Precision Score': 0.6158921107398279, 'AUC-PR': 0.8041114582693347}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.8232807049502298, 'F1 Score': 0.7395710184090525, 'Precision': 0.7605071205279611, 'Recall': 0.7197567389875082, 'AUROC': 0.9272017742406032, 'Average Precision Score': 0.6157880852469901, 'AUC-PR': 0.8024466005615527}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model()  # Multibird 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('checkpoints/bigbird_finetune_with_condition/mortality_1month_20000_patients/best.ckpt')\n",
    "# model['state_dict']['model.bert.embeddings.word_embeddings.weight'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
