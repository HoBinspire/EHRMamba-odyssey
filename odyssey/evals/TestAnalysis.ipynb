{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "\n",
    "ROOT = \"/fs01/home/afallah/odyssey/odyssey\"\n",
    "os.chdir(ROOT)\n",
    "\n",
    "from odyssey.data.dataset import FinetuneMultiDataset, FinetuneDatasetDecoder\n",
    "from odyssey.data.tokenizer import ConceptTokenizer\n",
    "from odyssey.models.model_utils import load_finetune_data, load_pretrain_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    \"\"\"Save the configuration arguments.\"\"\"\n",
    "\n",
    "    # test_outputs = \"checkpoints/mamba_finetune/test_outputs/test_outputs_f8471ffd.pt\"\n",
    "    test_outputs = \"checkpoints/mamba_finetune_with_embeddings/test_outputs/test_outputs_f521131a.pt\"\n",
    "    vocab_dir = \"odyssey/data/vocab\"\n",
    "    data_dir = \"odyssey/data/bigbird_data\"\n",
    "    sequence_file = \"patient_sequences_2048_multi.parquet\"\n",
    "    id_file = \"dataset_2048_multi.pkl\"\n",
    "    valid_scheme = \"few_shot\"\n",
    "    num_finetune_patients = \"all\"\n",
    "    # label_name = \"label_mortality_1month\"\n",
    "    tasks = ['mortality_1month', 'readmission_1month', 'los_1week', 'c0', 'c1', 'c2']\n",
    "\n",
    "    max_len = 2048\n",
    "    batch_size = 1\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_prob):\n",
    "    \"\"\"\n",
    "    Calculate and return performance metrics.\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"F1 Score\": f1_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred),\n",
    "        \"Recall\": recall_score(y_true, y_pred),\n",
    "        \"AUROC\": roc_auc_score(y_true, y_prob),\n",
    "        \"Average Precision Score\": average_precision_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    metrics[\"AUC-PR\"] = auc(recall, precision)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = ConceptTokenizer(data_dir=config.vocab_dir)\n",
    "tokenizer.fit_on_vocab()\n",
    "\n",
    "# Load pretrain data\n",
    "# pretrain = load_pretrain_data(\n",
    "#     config.data_dir,\n",
    "#     'patient_sequences/'+config.sequence_file,\n",
    "#     'patient_id_dict/'+config.id_file,\n",
    "# )\n",
    "\n",
    "# Load test data\n",
    "fine_tune, fine_test = load_finetune_data(\n",
    "    config.data_dir,\n",
    "    config.sequence_file,\n",
    "    config.id_file,\n",
    "    config.valid_scheme,\n",
    "    config.num_finetune_patients,\n",
    ")\n",
    "\n",
    "test_dataset = FinetuneDatasetDecoder(\n",
    "    data=fine_test,\n",
    "    tokenizer=tokenizer,\n",
    "    tasks=config.tasks,\n",
    "    balance_guide=None,\n",
    "    max_len=config.max_len,\n",
    ")\n",
    "\n",
    "# train_dataset = FinetuneMultiDataset(\n",
    "#             data=fine_tune,\n",
    "#             tokenizer=tokenizer,\n",
    "#             tasks=['mortality_1month', 'readmission_1month', 'los_1week', 'c0', 'c1', 'c2'],\n",
    "#             balance_guide={'mortality_1month':0.5, 'readmission_1month':0.5, 'los_1week':0.5, 'c0':0.5, 'c1':0.5, 'c2':0.5},\n",
    "#             max_len=config.max_len,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset Specifications\n",
    "------------------------\n",
    "\n",
    "Current Approach:\n",
    "    - Pretrain: 141234 Patients\n",
    "    - Test: 24924 Patients, 132682 Datapoints\n",
    "    - Finetune: 139514 Unique Patients, 434270 Datapoints\n",
    "        - Mortality: 26962 Patients\n",
    "        - Readmission: 48898 Patients\n",
    "        - Length of Stay: 72686 Patients\n",
    "        - Condition 0: 122722 Patients\n",
    "        - Condition 1: 94048 Patients\n",
    "        - Condition 2: 68954 Patients\n",
    "\n",
    "New Approach:\n",
    "    - Pretrain: . Patients\n",
    "    - Test: . Patients, . Datapoints\n",
    "    - Finetune: . Unique Patients, . Datapoints\n",
    "        - Mortality: . Patients\n",
    "        - Readmission: . Patients\n",
    "        - Length of Stay: . Patients\n",
    "        - Condition 0: . Patients\n",
    "        - Condition 1: . Patients\n",
    "        - Condition 2: . Patients\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasks we have are: tasks = ['mortality_1month', 'readmission_1month', 'los_1week', 'c0', 'c1', 'c2']\n",
    "\n",
    "tasks = [test_dataset.index_mapper[i][1] for i in range(len(test_dataset))]\n",
    "\n",
    "task2index = {task:[] for task in config.tasks}\n",
    "\n",
    "for i, task in enumerate(tasks):\n",
    "    task2index[task].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mortality_1month\n",
      "{'Balanced Accuracy': 0.9046091364922854, 'F1 Score': 0.6942788074133763, 'Precision': 0.573024740622506, 'Recall': 0.8806214227309894, 'AUROC': 0.9721118612424308, 'Average Precision Score': 0.5163334778180794, 'AUC-PR': 0.7326808894122636}\n",
      "\n",
      "Task: readmission_1month\n",
      "{'Balanced Accuracy': 0.6449577401436226, 'F1 Score': 0.5728762397585166, 'Precision': 0.5361178369652946, 'Recall': 0.6150462962962963, 'AUROC': 0.6999407465024068, 'Average Precision Score': 0.47572974018385267, 'AUC-PR': 0.6485782917207787}\n",
      "\n",
      "Task: los_1week\n",
      "{'Balanced Accuracy': 0.8231965165355855, 'F1 Score': 0.7355366174738447, 'Precision': 0.6648296593186372, 'Recall': 0.8230733447046054, 'AUROC': 0.9084304816895977, 'Average Precision Score': 0.6000398760543761, 'AUC-PR': 0.7703696543617022}\n",
      "\n",
      "Task: c0\n",
      "{'Balanced Accuracy': 0.8015438292543531, 'F1 Score': 0.7808362369337979, 'Precision': 0.738933311351084, 'Recall': 0.8277772647520547, 'AUROC': 0.8877116519104709, 'Average Precision Score': 0.6864996708299764, 'AUC-PR': 0.8207690258143682}\n",
      "\n",
      "Task: c1\n",
      "{'Balanced Accuracy': 0.8028137679799883, 'F1 Score': 0.7333600412064328, 'Precision': 0.6983106267029973, 'Recall': 0.7721137623523741, 'AUROC': 0.8908402771743532, 'Average Precision Score': 0.6150458920404646, 'AUC-PR': 0.7731475179107702}\n",
      "\n",
      "Task: c2\n",
      "{'Balanced Accuracy': 0.8356502594253696, 'F1 Score': 0.6895381715362865, 'Precision': 0.5581324382056759, 'Recall': 0.9018737672583826, 'AUROC': 0.9137024814312296, 'Average Precision Score': 0.527317821236009, 'AUC-PR': 0.741979511013204}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_outputs = torch.load(config.test_outputs, map_location=config.device)\n",
    "test_outputs.keys()\n",
    "\n",
    "labels = test_outputs[\"labels\"].cpu().numpy()\n",
    "logits = test_outputs[\"logits\"].cpu().numpy()\n",
    "probs = torch.sigmoid(torch.tensor(logits[:, 1])).cpu().numpy()\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "for task, task_idx in task2index.items():\n",
    "    print(f'Task: {task}')\n",
    "    print(calculate_metrics(labels[task_idx], preds[task_idx], probs[task_idx]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('checkpoints/bigbird_finetune_with_condition/mortality_1month_20000_patients/best.ckpt')\n",
    "# model['state_dict']['model.bert.embeddings.word_embeddings.weight'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
