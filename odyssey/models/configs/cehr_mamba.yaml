model:
  embedding_size: 768
  state_size: 16
  num_hidden_layers: 32
  expand: 2
  conv_kernel: 4
  dropout_prob: 0.1
  learning_rate: 5.e-5
  max_seq_length: 2048

model_finetune:
  learning_rate: 5.e-5
  classifier_dropout: 0.1

train:
  batch_size: 44 #32
  num_workers: 5
  gpus: 4
  nodes: 1
  max_epochs: 15
  acc: 1
  persistent_workers: True
  pin_memory: False

finetune:
  batch_size: 26
  num_workers: 6
  gpus: 4
  nodes: 1
  max_epochs: 5 #3
  acc: 1
  patience: 10
  persistent_workers: True
  pin_memory: False
