{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from itertools import chain\n",
    "from typing import Any, Dict, List, Optional, Set, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers\n",
    "from transformers import (\n",
    "    BatchEncoding,\n",
    "    PreTrainedTokenizerFast,\n",
    "    AutoTokenizer,\n",
    "    MambaConfig,\n",
    "    MambaModel,\n",
    "    MambaForCausalLM,\n",
    "    MambaPreTrainedModel\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from torch import nn, optim\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR, SequentialLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers.modeling_outputs import MaskedLMOutput, SequenceClassifierOutput\n",
    "\n",
    "# from mamba_ssm.models.mixer_seq_simple import MambaConfig, MambaLMHeadModel\n",
    "\n",
    "ROOT = \"/h/afallah/odyssey/odyssey\"\n",
    "os.chdir(ROOT)\n",
    "\n",
    "from odyssey.models.embeddings import *\n",
    "from odyssey.data.dataset import PretrainDataset, PretrainDatasetDecoder\n",
    "from odyssey.data.tokenizer import ConceptTokenizer\n",
    "from odyssey.models.cehr_bert.model import BertPretrain\n",
    "from odyssey.models.cehr_big_bird.model import BigBirdPretrain\n",
    "from odyssey.models.model_utils import (\n",
    "    get_run_id,\n",
    "    load_config,\n",
    "    load_pretrain_data,\n",
    "    load_finetune_data,\n",
    ")\n",
    "from odyssey.utils.utils import seed_everything\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    data_dir = 'odyssey/data/bigbird_data'\n",
    "    sequence_file = 'patient_sequences_2048_multi.parquet'\n",
    "    id_file = 'dataset_2048_multi.pkl'\n",
    "    vocab_dir = 'odyssey/data/vocab'\n",
    "    max_len = 2048\n",
    "    mask_prob = 0.15\n",
    "    tasks = ['mortality_1month', 'los_1week', 'c0', 'c1', 'c2']\n",
    "    balance_guide = {'mortality_1month': 0.5, 'los_1week': 0.5, 'c0': 0.5, 'c1': 0.5, 'c2': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tokenizer\n",
    "tokenizer = ConceptTokenizer(data_dir=args.vocab_dir)\n",
    "tokenizer.fit_on_vocab()\n",
    "\n",
    "\n",
    "# Setup data\n",
    "# pre_data = load_pretrain_data(\n",
    "#         args.data_dir,\n",
    "#         f'patient_sequences/{args.sequence_file}',\n",
    "#         f'patient_id_dict/{args.id_file}',\n",
    "# )\n",
    "# train_dataset = PretrainDatasetDecoder(\n",
    "#         data=pre_data,\n",
    "#         tokenizer=tokenizer,\n",
    "#         max_len=args.max_len,\n",
    "# )\n",
    "\n",
    "\n",
    "_, fine_test = load_finetune_data(\n",
    "    args.data_dir, args.sequence_file, args.id_file, \"few_shot\", \"all\"\n",
    ")\n",
    "test_dataset = PretrainDatasetDecoder(\n",
    "    data=fine_test,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=args.max_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaForCausalLM(\n",
       "  (backbone): MambaModel(\n",
       "    (embeddings): Embedding(20600, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MambaBlock(\n",
       "        (norm): MambaRMSNorm()\n",
       "        (mixer): MambaMixer(\n",
       "          (conv1d): Conv1d(1536, 1536, kernel_size=(4,), stride=(1,), padding=(3,), groups=1536)\n",
       "          (act): SiLU()\n",
       "          (in_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (x_proj): Linear(in_features=1536, out_features=80, bias=False)\n",
       "          (dt_proj): Linear(in_features=48, out_features=1536, bias=True)\n",
       "          (out_proj): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_f): MambaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=20600, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = MambaConfig(\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    hidden_size=768,\n",
    "    state_size=16,\n",
    "    num_hidden_layers=32,\n",
    "    max_seq_length=2048,\n",
    "    pad_token_id=tokenizer.get_pad_token_id(),\n",
    "    bos_token_id=tokenizer.token_to_id(\"[CLS]\"),\n",
    "    eos_token_id=tokenizer.get_pad_token_id(),\n",
    ")\n",
    "\n",
    "# embeddings = MambaEmbeddingsForCEHR(\n",
    "#     config=config\n",
    "# )\n",
    "\n",
    "model = MambaForCausalLM(config=config)\n",
    "# model.backbone.embeddings = embeddings\n",
    "model.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaForCausalLM(\n",
       "  (backbone): MambaModel(\n",
       "    (embeddings): Embedding(20600, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MambaBlock(\n",
       "        (norm): MambaRMSNorm()\n",
       "        (mixer): MambaMixer(\n",
       "          (conv1d): Conv1d(1536, 1536, kernel_size=(4,), stride=(1,), padding=(3,), groups=1536)\n",
       "          (act): SiLU()\n",
       "          (in_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (x_proj): Linear(in_features=1536, out_features=80, bias=False)\n",
       "          (dt_proj): Linear(in_features=48, out_features=1536, bias=True)\n",
       "          (out_proj): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_f): MambaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=20600, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "checkpoint = torch.load(\"checkpoints/mamba_pretrain/best.ckpt\", map_location=device)\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "state_dict = {k.replace(\"model.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(state_dict)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'concept_ids': tensor([[20592,     3, 17326,  ...,     0,     0,     0]], device='cuda:0'),\n",
       " 'labels': tensor([1], device='cuda:0'),\n",
       " 'task': 'mortality_1month'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "        decoder_dataset, #test_dataset, #train_dataset\n",
    "        batch_size=3,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "sample = decoder_dataset[2323] #test_dataset[8765] #train_dataset[0]\n",
    "task = sample.pop('task')\n",
    "sample = {key:tensor.unsqueeze(0).to(device) for key, tensor in sample.items()}\n",
    "sample['task'] = task\n",
    "\n",
    "# sample = next(iter(train_loader))\n",
    "# sample = {key:tensor.to(device) for key, tensor in sample.items()}\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MOR_1M] [VS] 58160087546 00904516561 00182853489 00574705050 00121054410 66553000401 00310027539 00006003121 00456320563 62856024541 00310027539 00172531210 00338069104 51006_2 50983_4 50971_2 50970_2 50960_3 50931_1 50912_2 50902_4 50893_3 50882_2 50868_2 51301_1 51279_4 51277_1 51265_2 51250_0 51248_1 51222_4 51221_4 00172531110 10432017002 10432017002 51006_2 50983_4 50971_3 50970_2 50960_3 50931_4 50912_3 50902_3 50893_4 50882_3 50868_3 51301_1 51279_4 51277_1 51265_1 51250_0 51248_1 51222_4 51221_4 00904224461 51301_2 51279_4 51277_1 51265_2 51250_0 51248_1 51222_4 51221_4 51006_2 50983_4 50971_3 50970_2 50960_2 50931_2 50912_3 50902_2 50893_3 50882_3 50868_4 [VE] [REG] [W_0] [VS] 8938 8838 8744 51006_2 50983_4 50971_2 50931_1 50912_2 50902_4 50882_3 50868_3 51301_1 51279_4 51277_1 51265_2 51256_1 51254_3 51250_1 51248_1 51244_3 51222_4 51221_4 51200_3 51146_2 63323026201 00713016550 00182844789 62856024541 00182853489 00904516561 00006003121 00121065721 10432017002 00182844789 66553000401 00904224461 00310027539 [VE] [REG] [M_2] [VS] 00338004304 63323026201 62856024541 00182844789 00310027539 10432017002 00904404073 00338004904 00456320563 66553000401 55390014710 51006_2 50983_3 50971_1 50970_0 50960_3 50931_2 50912_2 50902_4 50893_1 50882_2 50868_1 51301_2 51279_4 51277_1 51265_1 51250_1 51248_1 51222_4 51221_4 51006_2 50983_4 50971_0 50970_1 50960_2 50931_0 50912_2 50902_4 50893_2 50882_1 50868_3 00310027539 00172531210 00310027839 [VE] [REG] [LT] [VS] 51498_4 51491_0 33332001001 63323026201 00456320563 51079000220 60505258600 62856024541 60505258600 60505258600 51516_1 51498_4 51493_1 51491_0 51476_1 51301_0 51279_4 51277_1 51265_1 51250_0 51248_1 51222_4 51221_4 51006_2 50983_4 50971_1 50931_1 50912_2 50902_4 50893_3 50882_3 50868_1 60505258500 00310027539 [VE] [MOR_1M]\n"
     ]
    }
   ],
   "source": [
    "input_ids = sample[\"concept_ids\"].squeeze().tolist()\n",
    "input_ids = input_ids[: input_ids.index(0)]\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50931_1 50912_2 50902_4 50893_3 50882_3 50868_1 60505258500 00310027539 [VE] [MOR_1M]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50970_1 50960_2 50931_0 50912_2 50902_4 50893_3 50882_3 50868_1 [VE] [REG]'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    torch.tensor(input_ids[:-10], dtype=torch.int32).unsqueeze(0).to(device),\n",
    "    max_new_tokens=10,\n",
    ")\n",
    "\n",
    "tokenizer.decode(output.squeeze().tolist()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import AutoTokenizer, MambaForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "# model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "\n",
    "# inputs = tokenizer([\"Hello, my dog is cute\", \"NO\", \"Go to Sumeru\"], padding=True, return_tensors=\"pt\")\n",
    "# outputs = model(inputs['input_ids'], labels=inputs[\"input_ids\"])\n",
    "# loss = outputs.loss\n",
    "# logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "\n",
    "# model.backbone.embeddings.cache_input(\n",
    "#     token_type_ids_batch = sample['type_ids'],\n",
    "#     position_ids_batch = None,\n",
    "#     inputs_embeds = None,\n",
    "#     time_stamps = sample['time_stamps'],\n",
    "#     ages = sample['ages'],\n",
    "#     visit_orders = sample['visit_orders'],\n",
    "#     visit_segments = sample['visit_segments']\n",
    "# )\n",
    "\n",
    "# outputs = model(\n",
    "#     input_ids=sample[\"concept_ids\"], labels=sample[\"concept_ids\"], return_dict=True\n",
    "# )\n",
    "\n",
    "# loss = outputs.loss\n",
    "# logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 768])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = model.backbone\n",
    "outputs = model(\n",
    "    input_ids=sample[\"concept_ids\"], return_dict=True\n",
    ")\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'silu'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.hidden_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1596, -0.0591],\n",
       "         [ 0.2433, -1.0078],\n",
       "         [-0.3050, -0.3962],\n",
       "         ...,\n",
       "         [ 0.4917, -0.3203],\n",
       "         [ 0.4917, -0.3203],\n",
       "         [ 0.4917, -0.3203]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = torch.nn.Linear(config.hidden_size, 2, bias=False).to(device)\n",
    "logits = classifier(last_hidden_states)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20592, device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"concept_ids\"].squeeze()[204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([204], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_lengths = torch.eq(sample['concept_ids'], 0).int().argmax(-1) - 1\n",
    "sequence_lengths        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1697, -0.7979]], device='cuda:0', grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_logits = logits[torch.arange(1, device=device), sequence_lengths]\n",
    "pooled_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1697, -0.7979]], device='cuda:0', grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_last_hidden_states = last_hidden_states[torch.arange(1, device=device), sequence_lengths]\n",
    "classifier(pooled_last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0512, -0.2630]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "config_copy = copy.deepcopy(config)\n",
    "config_copy.classifier_dropout = 0.1\n",
    "head = MambaClassificationHead(config_copy).to(device)\n",
    "head(pooled_last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3221, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fct = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fct(pooled_logits.view(-1,2), torch.tensor([0]).to(device).view(-1))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odyssey.models.cehr_mamba.model import MambaPretrain\n",
    "from torch.nn import MSELoss, CrossEntropyLoss, BCEWithLogitsLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Emebeddings -> Not now\n",
    "2. Padding order -> Done automatically\n",
    "\n",
    "---\n",
    "Finetuning Approach:\n",
    "    1. Replace the first and last REG token with the class token\n",
    "2. Use the last hiddent state of the last token for class prediction\n",
    "3. Ourselves!\n",
    "\n",
    "4. Dataset refactoring (inheritance, what to return, etc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'concept_ids': tensor([20593,     3, 13054,  ...,     0,     0,     0]),\n",
       " 'labels': tensor(0),\n",
       " 'task': 'los_1week'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from odyssey.data.tokenizer import ConceptTokenizer, truncate_and_pad\n",
    "\n",
    "TASK_INDEX = 1\n",
    "LABEL_INDEX = 2\n",
    "CUTOFF_INDEX = 3\n",
    "\n",
    "\n",
    "class FinetuneDatasetDecoder(Dataset):\n",
    "    \"\"\"Dataset for finetuning a decoder-based model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The input data containing sequences to be tokenized and masked.\n",
    "    tokenizer : ConceptTokenizer\n",
    "        An instance of the ConceptTokenizer class used for tokenizing sequences.\n",
    "    tasks : List[str]\n",
    "        A list of tasks (labels) that need to be predicted.\n",
    "    balance_guide : Optional[Dict[str, float]], optional\n",
    "        A dictionary containing the desired positive ratios for each task,\n",
    "        by default None.\n",
    "    max_len : int, optional\n",
    "        The maximum length of the tokenized sequences, by default 2048.\n",
    "    nan_indicator : int, optional\n",
    "        Value used to represent missing labels in the dataset, by default -1.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Stores the input data.\n",
    "    tokenizer : ConceptTokenizer\n",
    "        Tokenizer used for tokenizing sequences.\n",
    "    tasks : List[str]\n",
    "        A list of tasks (labels) that need to be predicted.\n",
    "    balance_guide : Optional[Dict[str, float]]\n",
    "        A dictionary containing the desired positive ratios for each task.\n",
    "    max_len : int\n",
    "        Maximum length of the tokenized sequences.\n",
    "    nan_indicator : int\n",
    "        Value used to represent missing labels in the dataset.\n",
    "    task_to_index : Dict[str, List[Tuple[int, str, int, Optional[int]]]]\n",
    "        A dictionary mapping each task to a list of tuples containing the\n",
    "        index, task, label, and cutoff.\n",
    "    index_mapper : List[Tuple[int, str, int, Optional[int]]]\n",
    "        A list of all datapoints to be used by __getitem__.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: ConceptTokenizer,\n",
    "        tasks: List[str],\n",
    "        balance_guide: Optional[Dict[str, float]] = None,\n",
    "        max_len: int = 2048,\n",
    "        nan_indicator: int = -1,\n",
    "    ):\n",
    "        \"\"\"Initiate the class.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tasks = tasks  # List of tasks for which the model is being finetuned.\n",
    "        self.balance_guide = balance_guide\n",
    "        self.max_len = max_len\n",
    "        self.nan_indicator = (\n",
    "            nan_indicator  # Value used to indicate missing data in labels.\n",
    "        )\n",
    "\n",
    "        # Precompute indices for quick mapping in __getitem__ that\n",
    "        # exclude missing labels.\n",
    "        # This helps in filtering out entries where the label is missing\n",
    "        # for the specified tasks.\n",
    "        self.task_to_index = {task: [] for task in self.tasks}\n",
    "        self.data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        for patient in self.data.itertuples():\n",
    "            index = patient.Index\n",
    "\n",
    "            for task in self.tasks:\n",
    "                label_col = f\"label_{task}\"\n",
    "                # Skip this task for the current patient if the label is missing.\n",
    "                if getattr(patient, label_col) == self.nan_indicator:\n",
    "                    continue\n",
    "\n",
    "                label = getattr(patient, label_col)\n",
    "                # Check for the existence of a task-specific cutoff in the data,\n",
    "                # else use None.\n",
    "                if f\"cutoff_{task}\" in self.data.columns:\n",
    "                    cutoff = getattr(patient, f\"cutoff_{task}\")\n",
    "                else:\n",
    "                    cutoff = None\n",
    "                # Append a tuple containing the necessary information\n",
    "                # for training to index_mapper.\n",
    "                datapoint = (index, task, label, cutoff)\n",
    "                self.task_to_index[task].append(datapoint)\n",
    "\n",
    "        # Balance labels for specified tasks\n",
    "        if self.balance_guide:\n",
    "            for task in self.balance_guide:\n",
    "                self.balance_labels(task=task, positive_ratio=self.balance_guide[task])\n",
    "\n",
    "        # Create a list of all datapoints to be used by __getitem__\n",
    "        self.index_mapper = [\n",
    "            datapoints\n",
    "            for task_data in self.task_to_index.values()\n",
    "            for datapoints in task_data\n",
    "        ]\n",
    "        del self.task_to_index\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the length of dataset.\"\"\"\n",
    "        return len(self.index_mapper)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        \"\"\"Get data at corresponding index.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : int\n",
    "            The index of the data to be retrieved.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            A dictionary containing all different token sequences along with labels.\n",
    "        \"\"\"\n",
    "        index, task, labels, cutoff = self.index_mapper[idx]\n",
    "        data = self.data.iloc[index]\n",
    "\n",
    "        # Swap the first and last token with the task token.\n",
    "        data[f\"event_tokens_{self.max_len}\"][0] = self.tokenizer.task_to_token(task)\n",
    "        data[f\"event_tokens_{self.max_len}\"][-1] = self.tokenizer.task_to_token(task)\n",
    "\n",
    "        # Truncate and pad the data to the specified cutoff.\n",
    "        data = truncate_and_pad(data, cutoff, self.max_len)\n",
    "\n",
    "        # Prepare model input\n",
    "        tokenized_input = self.tokenize_data(data[f\"event_tokens_{self.max_len}\"])\n",
    "        concept_ids = tokenized_input[\"input_ids\"].squeeze()\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        return {\n",
    "            \"concept_ids\": concept_ids,\n",
    "            \"labels\": labels,\n",
    "            \"task\": task\n",
    "        }\n",
    "\n",
    "    def tokenize_data(self, sequence: Union[str, List[str]]) -> Any:\n",
    "        \"\"\"Tokenize the sequence and return input_ids and attention mask.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sequence : Union[str, List[str]]\n",
    "            The sequence to be tokenized.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Any\n",
    "            A dictionary containing input_ids and attention_mask.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.tokenizer(sequence, max_length=self.max_len)\n",
    "\n",
    "    def balance_labels(self, task: str, positive_ratio: float) -> None:\n",
    "        \"\"\"Balance the labels for the specified task in the dataset.\n",
    "\n",
    "        This function modifies the dataset to ensure that the ratio of positive samples\n",
    "        to the total number of samples matches the specified positive_ratio,\n",
    "        while keeping all positive data points.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        task : str\n",
    "            The task for which the labels need to be balanced.\n",
    "        positive_ratio : float\n",
    "            The desired positive ratio for the task.\n",
    "\n",
    "        \"\"\"\n",
    "        # Separate positive and negative datapoints\n",
    "        datapoints = self.task_to_index[task]\n",
    "        positives = [data for data in datapoints if data[LABEL_INDEX] == 1]\n",
    "        negatives = [data for data in datapoints if data[LABEL_INDEX] == 0]\n",
    "\n",
    "        # Calculate the total number of samples needed to achieve the\n",
    "        # desired positive ratio\n",
    "        num_positives = len(positives)\n",
    "        total_needed = int(num_positives / positive_ratio) - num_positives\n",
    "        num_negatives_to_keep = min(len(negatives), total_needed)\n",
    "\n",
    "        # Randomly select the negatives to keep\n",
    "        negatives_kept = random.sample(negatives, num_negatives_to_keep)\n",
    "\n",
    "        # Combine the kept negatives with all positives\n",
    "        self.task_to_index[task] = positives + negatives_kept\n",
    "\n",
    "\n",
    "decoder_dataset = FinetuneDatasetDecoder(\n",
    "        data=fine_test,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=args.max_len,\n",
    "        tasks=args.tasks,\n",
    "        balance_guide=args.balance_guide,\n",
    ")\n",
    "decoder_dataset[12112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MambaEmbeddingsForCEHR(nn.Module):\n",
    "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\"\"\"\n",
    "\n",
    "    # Copied from transformers.models.bert.modeling_bert.BertEmbeddings.__init__\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: MambaConfig,\n",
    "        max_position_embeddings: int = 2048,\n",
    "        type_vocab_size: int = 8,\n",
    "        time_embeddings_size: int = 16,\n",
    "        visit_order_size: int = 3,\n",
    "        layer_norm_eps: float = 1e-12,\n",
    "        hidden_dropout_prob: float = 0.1,\n",
    "    ) -> None:\n",
    "        \"\"\"Initiate wrapper class for embeddings used in BigBird CEHR classes.\"\"\"\n",
    "        super().__init__()\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.hidden_size = config.hidden_size\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(\n",
    "            config.vocab_size,\n",
    "            config.hidden_size,\n",
    "            padding_idx=config.pad_token_id,\n",
    "        )\n",
    "        self.position_embeddings = nn.Embedding(\n",
    "            self.max_position_embeddings,\n",
    "            config.hidden_size,\n",
    "        )\n",
    "        self.token_type_embeddings = nn.Embedding(\n",
    "            self.type_vocab_size,\n",
    "            config.hidden_size,\n",
    "        )\n",
    "        self.visit_order_embeddings = nn.Embedding(\n",
    "            self.max_position_embeddings,\n",
    "            config.hidden_size,\n",
    "        )\n",
    "        self.time_embeddings = TimeEmbeddingLayer(\n",
    "            embedding_size=time_embeddings_size,\n",
    "            is_time_delta=True,\n",
    "        )\n",
    "        self.age_embeddings = TimeEmbeddingLayer(\n",
    "            embedding_size=time_embeddings_size,\n",
    "        )\n",
    "        self.visit_segment_embeddings = VisitEmbedding(\n",
    "            visit_order_size=visit_order_size,\n",
    "            embedding_size=config.hidden_size,\n",
    "        )\n",
    "        self.scale_back_concat_layer = nn.Linear(\n",
    "            config.hidden_size + 2 * time_embeddings_size,\n",
    "            config.hidden_size,\n",
    "        )\n",
    "\n",
    "        self.time_stamps: Optional[torch.Tensor] = None\n",
    "        self.ages: Optional[torch.Tensor] = None\n",
    "        self.visit_orders: Optional[torch.Tensor] = None\n",
    "        self.visit_segments: Optional[torch.Tensor] = None\n",
    "\n",
    "        # self.LayerNorm is not snake-cased to stick with TensorFlow model\n",
    "        # variable name and be able to load any TensorFlow checkpoint file.\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=self.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(self.hidden_dropout_prob)\n",
    "\n",
    "        # position_ids (1, len position emb) is contiguous in memory.\n",
    "        self.position_embedding_type = getattr(\n",
    "            config,\n",
    "            \"position_embedding_type\",\n",
    "            \"absolute\",\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"position_ids\",\n",
    "            torch.arange(self.max_position_embeddings).expand((1, -1)),\n",
    "            persistent=False,\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"token_type_ids\",\n",
    "            torch.zeros(self.position_ids.size(), dtype=torch.long),\n",
    "            persistent=False,\n",
    "        )\n",
    "        # End copy\n",
    "\n",
    "    def cache_input(\n",
    "        self,\n",
    "        token_type_ids_batch: Optional[torch.Tensor] = None,\n",
    "        position_ids_batch: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        time_stamps: Optional[torch.Tensor] = None,\n",
    "        ages: Optional[torch.Tensor] = None,\n",
    "        visit_orders: Optional[torch.Tensor] = None,\n",
    "        visit_segments: Optional[torch.Tensor] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Cache values for time_stamps, ages, visit_orders & visit_segments.\n",
    "\n",
    "        These values will be used by the forward pass to change the final embedding.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        token_type_ids_batch : torch.Tensor\n",
    "            The token type IDs of the input data.\n",
    "        position_ids_batch : torch.Tensor\n",
    "            The position IDs of the input data.\n",
    "        inputs_embeds : torch.Tensor\n",
    "            The embeddings of the input data.\n",
    "        time_stamps : torch.Tensor\n",
    "            Time stamps of the input data.\n",
    "        ages : torch.Tensor\n",
    "            Ages of the input data.\n",
    "        visit_orders : torch.Tensor\n",
    "            Visit orders of the input data.\n",
    "        visit_segments : torch.Tensor\n",
    "            Visit segments of the input data.\n",
    "        \"\"\"\n",
    "        self.token_type_ids_batch = token_type_ids_batch\n",
    "        self.position_ids_batch = position_ids_batch\n",
    "        self.inputs_embeds = inputs_embeds\n",
    "        self.time_stamps = time_stamps\n",
    "        self.ages = ages\n",
    "        self.visit_orders = visit_orders\n",
    "        self.visit_segments = visit_segments\n",
    "\n",
    "    def clear_cache(self) -> None:\n",
    "        \"\"\"Delete the tensors cached by cache_input method.\"\"\"\n",
    "        del (\n",
    "            self.token_type_ids_batch,\n",
    "            self.position_ids_batch,\n",
    "            self.inputs_embeds,\n",
    "            self.time_stamps,\n",
    "            self.ages,\n",
    "            self.visit_orders,\n",
    "            self.visit_segments,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        past_key_values_length: int = 0,\n",
    "    ) -> Any:\n",
    "        \"\"\"Return the final embeddings of concept ids using input and cached values.\"\"\"\n",
    "        if input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        else:\n",
    "            input_shape = self.inputs_embeds.size()[:-1]\n",
    "\n",
    "        seq_length = input_shape[1]\n",
    "\n",
    "        if self.position_ids_batch is None:\n",
    "            self.position_ids_batch = self.position_ids[\n",
    "                :,\n",
    "                past_key_values_length : seq_length + past_key_values_length,\n",
    "            ]\n",
    "\n",
    "        # Setting the token_type_ids to the registered buffer in constructor\n",
    "        if self.token_type_ids_batch is None:\n",
    "            if hasattr(self, \"token_type_ids\"):\n",
    "                buffered_token_type_ids = self.token_type_ids[:, :seq_length]\n",
    "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(\n",
    "                    input_shape[0],\n",
    "                    seq_length,\n",
    "                )\n",
    "                self.token_type_ids_batch = buffered_token_type_ids_expanded\n",
    "            else:\n",
    "                self.token_type_ids_batch = torch.zeros(\n",
    "                    input_shape,\n",
    "                    dtype=torch.long,\n",
    "                    device=self.position_ids.device,\n",
    "                )\n",
    "\n",
    "        if self.inputs_embeds is None:\n",
    "            self.inputs_embeds = self.word_embeddings(input_ids)\n",
    "\n",
    "        # Using cached values from a prior cache_input call\n",
    "        time_stamps_embeds = self.time_embeddings(self.time_stamps)\n",
    "        ages_embeds = self.age_embeddings(self.ages)\n",
    "        visit_segments_embeds = self.visit_segment_embeddings(self.visit_segments)\n",
    "        visit_order_embeds = self.visit_order_embeddings(self.visit_orders)\n",
    "\n",
    "        position_embeds = self.position_embeddings(self.position_ids_batch)\n",
    "        token_type_embeds = self.token_type_embeddings(self.token_type_ids_batch)\n",
    "\n",
    "        self.inputs_embeds = torch.cat(\n",
    "            (self.inputs_embeds, time_stamps_embeds, ages_embeds),\n",
    "            dim=-1,\n",
    "        )\n",
    "        print(self.inputs_embeds.shape)\n",
    "        self.inputs_embeds = self.tanh(self.scale_back_concat_layer(self.inputs_embeds))\n",
    "        embeddings = self.inputs_embeds + token_type_embeds\n",
    "        embeddings += position_embeds\n",
    "        embeddings += visit_order_embeds\n",
    "        embeddings += visit_segments_embeds\n",
    "\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "\n",
    "        # Clear the cache for next forward call\n",
    "        self.clear_cache()\n",
    "\n",
    "        return embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
