{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: XGBoost.ipynb\n",
    "Code to train and evaluate an XGBoost model on MIMIC-IV FHIR dataset.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def Project():\n",
    "    \"\"\"\n",
    "    __Objectives__\n",
    "    0. Import data and separate unique visit tokens\n",
    "    1. Reduce the number of features (manual selection, hierarchy aggregation)\n",
    "    2. Create frequency features from event tokens\n",
    "    3. Include num_visits, youngest and oldest age, and maybe time\n",
    "    4. Use label column to create the prediction objective\n",
    "    5. Train XGBoost model and evaluate on test dataset\n",
    "\n",
    "    __Questions__\n",
    "    0. Why does CEHR-BERT only have 512 possible concept and time tokens? -> Probably most tokens are not present in the sample\n",
    "\n",
    "    __Extra__\n",
    "    Hyperparameters: {learning rate (LR), maximum tree depth (max depth), number of estimators (n estimators),\n",
    "                      column sampling by tree (colsample), row subsampling (subsample) and the regulation parameter Î±.}\n",
    "    \"\"\"\n",
    "    return ProjectObjectives.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "from scipy.sparse import csr_matrix, hstack, vstack, save_npz, load_npz\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "ROOT = \"../../data/baseline\"\n",
    "DATA_PATH = f\"{ROOT}/patient_sequences.parquet\"\n",
    "SAMPLE_DATA_PATH = f\"{ROOT}/CEHR-BERT_sample_patient_sequence.parquet\"\n",
    "FREQ_DF_PATH = f\"{ROOT}/patient_feature_freq.csv\"\n",
    "FREQ_MATRIX_PATH = f\"{ROOT}/patient_freq_matrix.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_parquet(DATA_PATH)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the unique set of all possible tokens, including special tokens\n",
    "unique_event_tokens = set()\n",
    "\n",
    "for patient_event_tokens in tqdm(\n",
    "    data[\"event_tokens_updated\"].values, desc=\"Loading Tokens\", unit=\" Patients\"\n",
    "):\n",
    "    for event_token in patient_event_tokens:\n",
    "        unique_event_tokens.add(event_token)\n",
    "\n",
    "unique_event_tokens = list(unique_event_tokens)\n",
    "unique_event_tokens.sort(reverse=True)\n",
    "\n",
    "print(\n",
    "    f\"Complete list of unique event tokens\\nLength: {len(unique_event_tokens)}\\nHead: {unique_event_tokens[:10]}...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_event_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\n",
    "    \"[PAD]\",\n",
    "    \"VS\",\n",
    "    \"VE\",\n",
    "    \"W_0\",\n",
    "    \"W_1\",\n",
    "    \"W_2\",\n",
    "    \"W_3\",\n",
    "    *[f\"M_{i}\" for i in range(0, 13)],\n",
    "    \"LT\",\n",
    "]\n",
    "feature_event_tokens = [\"id\"] + [\n",
    "    token for token in unique_event_tokens if token not in special_tokens\n",
    "]\n",
    "feature_event_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Get and save frequencies of each token for each patient sequence.  ###\n",
    "\n",
    "patient_freq_matrix = None\n",
    "buffer_size = 10000\n",
    "df_buffer = []\n",
    "matrix_buffer = []\n",
    "\n",
    "\n",
    "for idx, patient in tqdm(data.iterrows(), desc=\"Loading Tokens\", unit=\" Patients\"):\n",
    "    patient_history = {token: 0 for token in feature_event_tokens}\n",
    "    patient_history[\"id\"] = idx\n",
    "\n",
    "    for event_token in patient[\"event_tokens_updated\"]:\n",
    "        if event_token not in special_tokens:\n",
    "            patient_history[event_token] += 1\n",
    "\n",
    "    matrix_buffer.append(list(patient_history.values()))\n",
    "\n",
    "    if len(matrix_buffer) >= buffer_size:\n",
    "        current_matrix = csr_matrix(\n",
    "            matrix_buffer, shape=(len(matrix_buffer), len(feature_event_tokens))\n",
    "        )\n",
    "\n",
    "        if patient_freq_matrix is None:\n",
    "            patient_freq_matrix = current_matrix\n",
    "        else:\n",
    "            patient_freq_matrix = vstack(\n",
    "                [patient_freq_matrix, current_matrix], format=\"csr\"\n",
    "            )\n",
    "\n",
    "        matrix_buffer = []\n",
    "\n",
    "\n",
    "if matrix_buffer:\n",
    "    current_matrix = csr_matrix(\n",
    "        matrix_buffer, shape=(len(matrix_buffer), len(feature_event_tokens))\n",
    "    )\n",
    "\n",
    "    if patient_freq_matrix is None:\n",
    "        patient_freq_matrix = current_matrix\n",
    "    else:\n",
    "        patient_freq_matrix = vstack(\n",
    "            [patient_freq_matrix, current_matrix], format=\"csr\"\n",
    "        )\n",
    "\n",
    "    matrix_buffer = []\n",
    "\n",
    "\n",
    "save_npz(FREQ_MATRIX_PATH, patient_freq_matrix)\n",
    "print(f\"Save & Done! Final Matrix Shape: {patient_freq_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load frequency matrix\n",
    "patient_freq_matrix = load_npz(FREQ_MATRIX_PATH)\n",
    "num_patients = patient_freq_matrix.shape[0]\n",
    "patient_freq_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_greater_than_zero(lst):\n",
    "    positive_numbers = np.array(lst)[np.array(lst) > 0]\n",
    "\n",
    "    if len(positive_numbers) == 0:\n",
    "        return 0\n",
    "\n",
    "    min_positive = np.min(positive_numbers)\n",
    "    return min_positive\n",
    "\n",
    "\n",
    "# Get extra features\n",
    "num_visits = data[\"num_visits\"].values\n",
    "min_age = [\n",
    "    find_min_greater_than_zero(patient_age_tokens)\n",
    "    for patient_age_tokens in data[\"age_tokens\"]\n",
    "]\n",
    "max_age = [np.max(patient_age_tokens) for patient_age_tokens in data[\"age_tokens\"]]\n",
    "\n",
    "# Add extra features to the frequency dataset\n",
    "patient_freq_matrix = hstack(\n",
    "    [patient_freq_matrix, csr_matrix([num_visits, min_age, max_age]).T], format=\"csr\"\n",
    ")\n",
    "patient_freq_matrix = patient_freq_matrix[:, 1:]  # Drop id feature\n",
    "patient_freq_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get intuition about the frequency of different features in the dataset\n",
    "report_threshold = 50\n",
    "features_above_threshold = np.sum(\n",
    "    (patient_freq_matrix.getnnz(axis=0) > report_threshold).astype(int)\n",
    ")\n",
    "print(\n",
    "    f\"How many features have been reported for at least {report_threshold} patients?\\n{features_above_threshold} Features\"\n",
    ")\n",
    "\n",
    "# Plot the histogram of feature frequency\n",
    "# plt.hist(patient_freq_matrix.getnnz(axis=0), bins=range(num_patients+1), edgecolor='black')\n",
    "# plt.xlabel('Number of Nonzero Rows')\n",
    "# plt.ylabel('Number of Columns')\n",
    "# plt.title('Histogram of Nonzero Rows per Column')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick features to train the model on\n",
    "NUM_FEATURES = 5000\n",
    "features_sorted_by_freq = np.argsort(-patient_freq_matrix.getnnz(axis=0))\n",
    "selected_features = features_sorted_by_freq[: NUM_FEATURES + 1]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for model training\n",
    "X = patient_freq_matrix[:, selected_features]\n",
    "Y = data[\"label\"].values\n",
    "\n",
    "# Optional, Scale features. Didn't improve performance\n",
    "scaler = MaxAbsScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, stratify=Y, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=23)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ASSESS MODEL PERFORMANCE ###\n",
    "\n",
    "# Predict labels for train, test, and all data\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "all_data_pred = xgb_model.predict(X)\n",
    "\n",
    "# Balanced Accuracy\n",
    "y_train_accuracy = balanced_accuracy_score(y_train, y_train_pred)\n",
    "y_test_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "all_data_accuracy = balanced_accuracy_score(Y, all_data_pred)\n",
    "\n",
    "# F1 Score\n",
    "y_train_f1 = f1_score(y_train, y_train_pred)\n",
    "y_test_f1 = f1_score(y_test, y_test_pred)\n",
    "all_data_f1 = f1_score(Y, all_data_pred)\n",
    "\n",
    "# Precision\n",
    "y_train_precision = precision_score(y_train, y_train_pred)\n",
    "y_test_precision = precision_score(y_test, y_test_pred)\n",
    "all_data_precision = precision_score(Y, all_data_pred)\n",
    "\n",
    "# Recall\n",
    "y_train_recall = recall_score(y_train, y_train_pred)\n",
    "y_test_recall = recall_score(y_test, y_test_pred)\n",
    "all_data_recall = recall_score(Y, all_data_pred)\n",
    "\n",
    "# AUROC\n",
    "y_train_auroc = roc_auc_score(y_train, y_train_pred)\n",
    "y_test_auroc = roc_auc_score(y_test, y_test_pred)\n",
    "all_data_auroc = roc_auc_score(Y, all_data_pred)\n",
    "\n",
    "# AUC-PR (Area Under the Precision-Recall Curve)\n",
    "y_train_p, y_train_r, _ = precision_recall_curve(y_train, y_train_pred)\n",
    "y_test_p, y_test_r, _ = precision_recall_curve(y_test, y_test_pred)\n",
    "all_data_p, all_data_r, _ = precision_recall_curve(Y, all_data_pred)\n",
    "\n",
    "y_train_auc_pr = auc(y_train_r, y_train_p)\n",
    "y_test_auc_pr = auc(y_test_r, y_test_p)\n",
    "all_data_auc_pr = auc(all_data_r, all_data_p)\n",
    "\n",
    "# Average Precision Score (APS)\n",
    "y_train_aps = average_precision_score(y_train, y_train_pred)\n",
    "y_test_aps = average_precision_score(y_test, y_test_pred)\n",
    "all_data_aps = average_precision_score(Y, all_data_pred)\n",
    "\n",
    "# Print Metrics\n",
    "print(\n",
    "    f\"Balanced Accuracy\\nTrain: {y_train_accuracy:.5f}  |  Test: {y_test_accuracy:.5f}  |  All Data: {all_data_accuracy:.5f}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"F1 Score\\nTrain: {y_train_f1:.5f}  |  Test: {y_test_f1:.5f}  |  All Data: {all_data_f1:.5f}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"Precision\\nTrain: {y_train_precision:.5f}  |  Test: {y_test_precision:.5f}  |  All Data: {all_data_precision:.5f}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"Recall\\nTrain: {y_train_recall:.5f}  |  Test: {y_test_recall:.5f}  |  All Data: {all_data_recall:.5f}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"AUROC\\nTrain: {y_train_auroc:.5f}  |  Test: {y_test_auroc:.5f}  |  All Data: {all_data_auroc:.5f}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"AUC-PR\\nTrain: {y_train_auc_pr:.5f}  |  Test: {y_test_auc_pr:.5f}  |  All Data: {all_data_auc_pr:.5f}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"Average Precision Score\\nTrain: {y_train_aps:.5f}  |  Test: {y_test_aps:.5f}  |  All Data: {all_data_aps:.5f}\\n\"\n",
    ")\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred)\n",
    "fpr_all_data, tpr_all_data, _ = roc_curve(Y, all_data_pred)\n",
    "\n",
    "# Plot Information\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr_train, tpr_train, label=f\"Train AUROC={y_train_auroc:.2f}\")\n",
    "plt.plot(fpr_test, tpr_test, label=f\"Test AUROC={y_test_auroc:.2f}\")\n",
    "plt.plot(fpr_all_data, tpr_all_data, label=f\"All Data AUROC={all_data_auroc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCRIPT FOR K-FOLD VALIDATION ###\n",
    "N_FOLDS = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "stratified_kfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store performance metrics for each fold\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "aurocs = []\n",
    "auc_prs = []\n",
    "average_precision_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in tqdm(\n",
    "    stratified_kfold.split(X, Y), desc=f\"{N_FOLDS}-Fold Validation\", unit=\" Model(s)\"\n",
    "):\n",
    "    # Get the relevant train and test data\n",
    "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_test_fold = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Create a new XGBoost model for each fold\n",
    "    xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=23)\n",
    "\n",
    "    # Train the model on the training fold\n",
    "    xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predict on the test fold\n",
    "    y_pred_fold = xgb_model.predict(X_test_fold)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    accuracy_fold = balanced_accuracy_score(y_test_fold, y_pred_fold)\n",
    "    f1_fold = f1_score(y_test_fold, y_pred_fold)\n",
    "    precision_fold = precision_score(y_test_fold, y_pred_fold)\n",
    "    recall_fold = recall_score(y_test_fold, y_pred_fold)\n",
    "    auroc_fold = roc_auc_score(y_test_fold, y_pred_fold)\n",
    "    p_fold, r_fold, _ = precision_recall_curve(y_test_fold, y_pred_fold)\n",
    "    auc_pr_fold = auc(r_fold, p_fold)\n",
    "    average_precision_score_fold = average_precision_score(y_test_fold, y_pred_fold)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "    f1_scores.append(f1_fold)\n",
    "    precisions.append(precision_fold)\n",
    "    recalls.append(recall_fold)\n",
    "    aurocs.append(auroc_fold)\n",
    "    auc_prs.append(auc_pr_fold)\n",
    "    average_precision_scores.append(average_precision_score_fold)\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"Average Balanced Accuracy: {sum(accuracy_scores) / N_FOLDS:.5f}\")\n",
    "print(f\"Average F1 Score: {sum(f1_scores) / N_FOLDS:.5f}\")\n",
    "print(f\"Average Precision: {sum(precisions) / N_FOLDS:.5f}\")\n",
    "print(f\"Average Recall: {sum(recalls) / N_FOLDS:.5f}\")\n",
    "print(f\"Average AUROC: {sum(aurocs) / N_FOLDS:.5f}\")\n",
    "print(f\"Average AUC-PR: {sum(auc_prs) / N_FOLDS:.5f}\")\n",
    "print(f\"Average Precision Score: {sum(average_precision_scores) / N_FOLDS:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
