{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:17:53.451568Z",
     "start_time": "2024-03-18T02:17:53.443199Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: XGBoost.ipynb\n",
    "Code to train and evaluate an XGBoost model on MIMIC-IV FHIR dataset.\n",
    "\"\"\"\n",
    "\n",
    "def ProjectObjectives():\n",
    "    \"\"\"\n",
    "    __Objectives__\n",
    "    0. Import data and separate unique visit tokens\n",
    "    1. Reduce the number of features (manual selection, hierarchy aggregation)\n",
    "    2. Create frequency features from event tokens\n",
    "    3. Include num_visits, youngest and oldest age, and maybe time\n",
    "    4. Use label column to create the prediction objective\n",
    "    5. Train XGBoost model and evaluate on test dataset\n",
    "    >>> All objectives successful\n",
    "    \"\"\"\n",
    "    return ProjectObjectives.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:17:54.970742Z",
     "start_time": "2024-03-18T02:17:53.455747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import dependencies and define useful constants\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from typing import Any, List, Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from scipy.sparse import csr_matrix, hstack, load_npz, save_npz, vstack\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "%matplotlib inline\n",
    "\n",
    "ROOT = \"/fs01/home/afallah/odyssey/odyssey\"\n",
    "os.chdir(ROOT)\n",
    "\n",
    "TASK = 'readmission'\n",
    "NUM_PATIENTS = '50000'\n",
    "DATA_ROOT = f\"{ROOT}/data/bigbird_data/old_data\"\n",
    "DATA_PATH = f\"{DATA_ROOT}/patient_sequences/patient_sequences_2048_{TASK}.parquet\"\n",
    "ID_PATH = f\"{DATA_ROOT}/patient_id_dict/dataset_2048_{TASK}_1month.pkl\"\n",
    "FREQ_MATRIX_TRAIN = f\"{DATA_ROOT}/patient_freq_matrix/{TASK}/patient_freq_matrix_finetune_{NUM_PATIENTS}.npz\"\n",
    "FREQ_MATRIX_TEST = f\"{DATA_ROOT}/patient_freq_matrix/{TASK}/patient_freq_matrix_test.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:18:02.554807Z",
     "start_time": "2024-03-18T02:17:54.972637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>num_visits</th>\n",
       "      <th>token_length</th>\n",
       "      <th>event_tokens_2048</th>\n",
       "      <th>type_tokens_2048</th>\n",
       "      <th>age_tokens_2048</th>\n",
       "      <th>time_tokens_2048</th>\n",
       "      <th>visit_tokens_2048</th>\n",
       "      <th>position_tokens_2048</th>\n",
       "      <th>elapsed_tokens_2048</th>\n",
       "      <th>label</th>\n",
       "      <th>rare_conditions</th>\n",
       "      <th>last_VS_index</th>\n",
       "      <th>label_readmission_1month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f5bba8dd-25c0-5336-8d3d-37424c185026</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>[CLS] [VS] 52135_2 52075_2 52074_2 52073_3 520...</td>\n",
       "      <td>[1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[0, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83...</td>\n",
       "      <td>[0, 6594, 6594, 6594, 6594, 6594, 6594, 6594, ...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-2.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f4938f91-cadb-5133-8541-a52fb0916cea</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>[CLS] [VS] 0RB30ZZ 0RG10A0 00071101441 0090419...</td>\n",
       "      <td>[1, 2, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>[0, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44...</td>\n",
       "      <td>[0, 8150, 8150, 8150, 8150, 8150, 8150, 8150, ...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-2.0, -1.0, 0.0, 0.0, 1.08, 1.08, 13.89, 13.8...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6fe2371b-a6f0-5436-aade-7795005b0c66</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>[CLS] [VS] 63739057310 49281041688 00597026010...</td>\n",
       "      <td>[1, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>[0, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72...</td>\n",
       "      <td>[0, 6093, 6093, 6093, 6093, 6093, 6093, 6093, ...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-2.0, -1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.7...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7376b52c-8e7e-5e5d-b256-1892a7237694</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>[CLS] [VS] 00071041813 00121197100 00904198261...</td>\n",
       "      <td>[1, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>[0, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79...</td>\n",
       "      <td>[0, 8451, 8451, 8451, 8451, 8451, 8451, 8451, ...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-2.0, -1.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e0bb4cea-1ae3-5716-baa0-b93d56001be8</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>[CLS] [VS] 51006_0 50983_0 50971_1 50946_4 509...</td>\n",
       "      <td>[1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28...</td>\n",
       "      <td>[0, 8342, 8342, 8342, 8342, 8342, 8342, 8342, ...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-2.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75455</th>\n",
       "      <td>cf2115d7-937e-511d-b159-dd7eb3d5d420</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>[CLS] [VS] 33332001001 00781305714 10019017644...</td>\n",
       "      <td>[1, 2, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 6, 5, ...</td>\n",
       "      <td>[0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32...</td>\n",
       "      <td>[0, 5481, 5481, 5481, 5481, 5481, 5481, 5481, ...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-2.0, -1.0, 1.16, 1.25, 1.3, 1.3, 1.31, 1.53,...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75456</th>\n",
       "      <td>31338a39-28f9-54a5-a810-2d05fbaa5166</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "      <td>[CLS] [VS] 00338011704 00409128331 63323026201...</td>\n",
       "      <td>[1, 2, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[0, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50...</td>\n",
       "      <td>[0, 4997, 4997, 4997, 4997, 4997, 4997, 4997, ...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-2.0, -1.0, 1.48, 1.49, 1.52, 1.52, 1.6, 1.6,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75457</th>\n",
       "      <td>0989415d-394c-5f42-8dac-75dc7306a23c</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[CLS] [VS] 49281041550 51079043620 51079088120...</td>\n",
       "      <td>[1, 2, 6, 6, 6, 6, 6, 6, 6, 3, 8, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 0,...</td>\n",
       "      <td>[0, 5309, 5309, 5309, 5309, 5309, 5309, 5309, ...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-2.0, -1.0, 1.3, 1.78, 1.78, 1.78, 1.84, 1.94...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75458</th>\n",
       "      <td>26fb8fef-b976-5c55-859d-cc190261f94b</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>[CLS] [VS] 0SRD0J9 00904224461 00409128331 009...</td>\n",
       "      <td>[1, 2, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>[0, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61...</td>\n",
       "      <td>[0, 5075, 5075, 5075, 5075, 5075, 5075, 5075, ...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-2.0, -1.0, 0.0, 23.94, 23.94, 23.94, 23.94, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75459</th>\n",
       "      <td>02cee673-6875-50c9-bad9-e7a7746731eb</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>[CLS] [VS] 33332001101 00904224461 00904516561...</td>\n",
       "      <td>[1, 2, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>[0, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52...</td>\n",
       "      <td>[0, 5642, 5642, 5642, 5642, 5642, 5642, 5642, ...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-2.0, -1.0, 2.64, 2.71, 2.71, 4.15, 4.15, 4.4...</td>\n",
       "      <td>[1, 0, 1, 1, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75460 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 patient_id  num_visits  token_length  \\\n",
       "0      f5bba8dd-25c0-5336-8d3d-37424c185026           1            67   \n",
       "1      f4938f91-cadb-5133-8541-a52fb0916cea           1            48   \n",
       "2      6fe2371b-a6f0-5436-aade-7795005b0c66           1            54   \n",
       "3      7376b52c-8e7e-5e5d-b256-1892a7237694           1            38   \n",
       "4      e0bb4cea-1ae3-5716-baa0-b93d56001be8           3           143   \n",
       "...                                     ...         ...           ...   \n",
       "75455  cf2115d7-937e-511d-b159-dd7eb3d5d420           1           108   \n",
       "75456  31338a39-28f9-54a5-a810-2d05fbaa5166           2           191   \n",
       "75457  0989415d-394c-5f42-8dac-75dc7306a23c           1            11   \n",
       "75458  26fb8fef-b976-5c55-859d-cc190261f94b           1            77   \n",
       "75459  02cee673-6875-50c9-bad9-e7a7746731eb           1            38   \n",
       "\n",
       "                                       event_tokens_2048  \\\n",
       "0      [CLS] [VS] 52135_2 52075_2 52074_2 52073_3 520...   \n",
       "1      [CLS] [VS] 0RB30ZZ 0RG10A0 00071101441 0090419...   \n",
       "2      [CLS] [VS] 63739057310 49281041688 00597026010...   \n",
       "3      [CLS] [VS] 00071041813 00121197100 00904198261...   \n",
       "4      [CLS] [VS] 51006_0 50983_0 50971_1 50946_4 509...   \n",
       "...                                                  ...   \n",
       "75455  [CLS] [VS] 33332001001 00781305714 10019017644...   \n",
       "75456  [CLS] [VS] 00338011704 00409128331 63323026201...   \n",
       "75457  [CLS] [VS] 49281041550 51079043620 51079088120...   \n",
       "75458  [CLS] [VS] 0SRD0J9 00904224461 00409128331 009...   \n",
       "75459  [CLS] [VS] 33332001101 00904224461 00904516561...   \n",
       "\n",
       "                                        type_tokens_2048  \\\n",
       "0      [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "1      [1, 2, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...   \n",
       "2      [1, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...   \n",
       "3      [1, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...   \n",
       "4      [1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "...                                                  ...   \n",
       "75455  [1, 2, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 6, 5, ...   \n",
       "75456  [1, 2, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "75457  [1, 2, 6, 6, 6, 6, 6, 6, 6, 3, 8, 0, 0, 0, 0, ...   \n",
       "75458  [1, 2, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...   \n",
       "75459  [1, 2, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, ...   \n",
       "\n",
       "                                         age_tokens_2048  \\\n",
       "0      [0, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83...   \n",
       "1      [0, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44...   \n",
       "2      [0, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72...   \n",
       "3      [0, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79...   \n",
       "4      [0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28...   \n",
       "...                                                  ...   \n",
       "75455  [0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32...   \n",
       "75456  [0, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50...   \n",
       "75457  [0, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 0,...   \n",
       "75458  [0, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61...   \n",
       "75459  [0, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52...   \n",
       "\n",
       "                                        time_tokens_2048  \\\n",
       "0      [0, 6594, 6594, 6594, 6594, 6594, 6594, 6594, ...   \n",
       "1      [0, 8150, 8150, 8150, 8150, 8150, 8150, 8150, ...   \n",
       "2      [0, 6093, 6093, 6093, 6093, 6093, 6093, 6093, ...   \n",
       "3      [0, 8451, 8451, 8451, 8451, 8451, 8451, 8451, ...   \n",
       "4      [0, 8342, 8342, 8342, 8342, 8342, 8342, 8342, ...   \n",
       "...                                                  ...   \n",
       "75455  [0, 5481, 5481, 5481, 5481, 5481, 5481, 5481, ...   \n",
       "75456  [0, 4997, 4997, 4997, 4997, 4997, 4997, 4997, ...   \n",
       "75457  [0, 5309, 5309, 5309, 5309, 5309, 5309, 5309, ...   \n",
       "75458  [0, 5075, 5075, 5075, 5075, 5075, 5075, 5075, ...   \n",
       "75459  [0, 5642, 5642, 5642, 5642, 5642, 5642, 5642, ...   \n",
       "\n",
       "                                       visit_tokens_2048  \\\n",
       "0      [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "1      [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "2      [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "3      [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "4      [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "...                                                  ...   \n",
       "75455  [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "75456  [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "75457  [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, ...   \n",
       "75458  [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "75459  [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "\n",
       "                                    position_tokens_2048  \\\n",
       "0      [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1      [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2      [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3      [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4      [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                  ...   \n",
       "75455  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "75456  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "75457  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...   \n",
       "75458  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "75459  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                     elapsed_tokens_2048  \\\n",
       "0      [-2.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "1      [-2.0, -1.0, 0.0, 0.0, 1.08, 1.08, 13.89, 13.8...   \n",
       "2      [-2.0, -1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.7...   \n",
       "3      [-2.0, -1.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0...   \n",
       "4      [-2.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "...                                                  ...   \n",
       "75455  [-2.0, -1.0, 1.16, 1.25, 1.3, 1.3, 1.31, 1.53,...   \n",
       "75456  [-2.0, -1.0, 1.48, 1.49, 1.52, 1.52, 1.6, 1.6,...   \n",
       "75457  [-2.0, -1.0, 1.3, 1.78, 1.78, 1.78, 1.84, 1.94...   \n",
       "75458  [-2.0, -1.0, 0.0, 23.94, 23.94, 23.94, 23.94, ...   \n",
       "75459  [-2.0, -1.0, 2.64, 2.71, 2.71, 4.15, 4.15, 4.4...   \n",
       "\n",
       "                                label                 rare_conditions  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2      [1, 0, 0, 0, 0, 0, 0, 1, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "...                               ...                             ...   \n",
       "75455  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "75456  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "75457  [0, 0, 0, 0, 1, 0, 0, 0, 1, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "75458  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "75459  [1, 0, 1, 1, 0, 1, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "       last_VS_index  label_readmission_1month  \n",
       "0                 68                         0  \n",
       "1                 49                         1  \n",
       "2                 55                         0  \n",
       "3                 39                         1  \n",
       "4                144                         1  \n",
       "...              ...                       ...  \n",
       "75455            109                         1  \n",
       "75456            192                         0  \n",
       "75457             12                         0  \n",
       "75458             78                         0  \n",
       "75459             39                         0  \n",
       "\n",
       "[75460 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet(f\"{ROOT}/data/bigbird_data/patient_sequences/patient_sequences_2048_{TASK}.parquet\")\n",
    "dataset.rename(columns={f'common_conditions': 'label'}, inplace=True)\n",
    "# dataset.rename(columns={f'label_{TASK}_1month': 'label'}, inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:18:02.652563Z",
     "start_time": "2024-03-18T02:18:02.557851Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patient_ids = pickle.load(open(ID_PATH, 'rb'))\n",
    "train_data = dataset.loc[dataset['patient_id'].isin(patient_ids[\"finetune\"]['few_shot'][NUM_PATIENTS])]\n",
    "test_data = dataset.loc[dataset['patient_id'].isin(patient_ids['test'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:18:07.521714Z",
     "start_time": "2024-03-18T02:18:02.654221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Tokens: 100%|██████████| 75460/75460 [00:05<00:00, 14778.71 Patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete list of unique event tokens\n",
      "Length: 16458\n",
      "Head: ['[W_3]', '[W_2]', '[W_1]', '[W_0]', '[VS]', '[VE]', '[REG]', '[M_9]', '[M_8]', '[M_7]', '[M_6]', '[M_5]', '[M_4]', '[M_3]', '[M_2]', '[M_1]', '[M_12]', '[M_11]', '[M_10]', '[M_0]', '[LT]', '[CLS]', 'XY0VX83', 'XW0DXR5', 'XW0DX82', 'XW043C3', 'XW043B3', 'XW04351', 'XW033B3', 'XW03331']...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the unique set of all possible tokens, including special tokens\n",
    "unique_event_tokens = set()\n",
    "\n",
    "for patient_event_tokens in tqdm(\n",
    "        dataset[\"event_tokens_2048\"].values,\n",
    "        desc=\"Loading Tokens\",\n",
    "        unit=\" Patients\",\n",
    "):\n",
    "    for event_token in patient_event_tokens.split(' '):\n",
    "        unique_event_tokens.add(event_token)\n",
    "\n",
    "unique_event_tokens = list(unique_event_tokens)\n",
    "unique_event_tokens.sort(reverse=True)\n",
    "\n",
    "print(\n",
    "    f\"Complete list of unique event tokens\\nLength: {len(unique_event_tokens)}\\nHead: {unique_event_tokens[:30]}...\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:18:07.534354Z",
     "start_time": "2024-03-18T02:18:07.523148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16437 ['id', 'XY0VX83', 'XW0DXR5', 'XW0DX82', 'XW043C3', 'XW043B3', 'XW04351', 'XW033B3', 'XW03331', 'X2RF332', 'X2C1361', 'X2C0361', 'X2A5312', 'HZ87ZZZ', 'HZ85ZZZ', 'HZ2ZZZZ', 'GZB4ZZZ', 'GZB2ZZZ', 'GZB1ZZZ', 'GZB0ZZZ']\n"
     ]
    }
   ],
   "source": [
    "# Define the list of tokens being used as features for the XGBoost\n",
    "# Note that feature 'id' will be dropped later on\n",
    "special_tokens = [\n",
    "    \"[CLS]\",\n",
    "    \"[PAD]\",\n",
    "    \"[REG]\",\n",
    "    \"[UNK]\",\n",
    "    \"[VS]\",\n",
    "    \"[VE]\",\n",
    "    \"[W_0]\",\n",
    "    \"[W_1]\",\n",
    "    \"[W_2]\",\n",
    "    \"[W_3]\",\n",
    "    *[f\"[M_{i}]\" for i in range(0, 13)],\n",
    "    \"[LT]\",\n",
    "]\n",
    "\n",
    "feature_event_tokens = [\"id\"] + [\n",
    "    token for token in unique_event_tokens if token not in special_tokens\n",
    "]\n",
    "\n",
    "print(len(feature_event_tokens), feature_event_tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:25:27.580887Z",
     "start_time": "2024-03-18T02:22:17.577626Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate feature frequency matrix for each feature token in the patient data\n",
    "# Since this will be saved to disk, you need only do it once\n",
    "def get_patient_frequency_matrix(\n",
    "        data: pd.DataFrame,\n",
    "        feature_event_tokens: List[str],\n",
    "        special_tokens: List[str],\n",
    "        output_path: str,\n",
    "        buffer_size: int = 50000) -> None:\n",
    "    \"\"\" Calculate and save the patient frequency matrix. \"\"\"\n",
    "\n",
    "    patient_freq_matrix = None\n",
    "    matrix_buffer = []\n",
    "\n",
    "    for idx, patient in tqdm(data.iterrows(), desc=\"Loading Tokens\", unit=\" Patients\", total=len(data)):\n",
    "        patient_history = {token: 0 for token in feature_event_tokens}\n",
    "        patient_history[\"id\"] = idx\n",
    "\n",
    "        for event_token in patient[\"event_tokens_2048\"].split(' '):\n",
    "            if event_token not in special_tokens:\n",
    "                patient_history[event_token] += 1\n",
    "\n",
    "        matrix_buffer.append(list(patient_history.values()))\n",
    "\n",
    "        if len(matrix_buffer) >= buffer_size:\n",
    "            current_matrix = csr_matrix(\n",
    "                matrix_buffer, shape=(len(matrix_buffer), len(feature_event_tokens)),\n",
    "            )\n",
    "\n",
    "            if patient_freq_matrix is None:\n",
    "                patient_freq_matrix = current_matrix\n",
    "            else:\n",
    "                patient_freq_matrix = vstack(\n",
    "                    [patient_freq_matrix, current_matrix], format=\"csr\",\n",
    "                )\n",
    "\n",
    "            matrix_buffer = []\n",
    "\n",
    "\n",
    "    if matrix_buffer:\n",
    "        current_matrix = csr_matrix(\n",
    "            matrix_buffer, shape=(len(matrix_buffer), len(feature_event_tokens)),\n",
    "        )\n",
    "\n",
    "        if patient_freq_matrix is None:\n",
    "            patient_freq_matrix = current_matrix\n",
    "        else:\n",
    "            patient_freq_matrix = vstack(\n",
    "                [patient_freq_matrix, current_matrix], format=\"csr\",\n",
    "            )\n",
    "\n",
    "    save_npz(output_path, patient_freq_matrix)\n",
    "    print(f\"Save & Done! Final Matrix Shape: {patient_freq_matrix.shape}\\n\")\n",
    "\n",
    "# get_patient_frequency_matrix(train_data, feature_event_tokens, special_tokens, output_path=FREQ_MATRIX_TRAIN)\n",
    "# get_patient_frequency_matrix(test_data, feature_event_tokens, special_tokens, output_path=FREQ_MATRIX_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:41:37.007429Z",
     "start_time": "2024-03-18T02:41:36.683489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50000x16343 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6072798 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load feature frequency matrix from disk, generated by above code cell\n",
    "patient_freq_matrix = load_npz(FREQ_MATRIX_TRAIN)\n",
    "patient_freq_matrix_test = load_npz(FREQ_MATRIX_TEST)\n",
    "num_patients = patient_freq_matrix.shape[0] + patient_freq_matrix_test.shape[0]\n",
    "patient_freq_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:41:37.481671Z",
     "start_time": "2024-03-18T02:41:37.472431Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_min_greater_than_zero(lst: List[int]) -> int:\n",
    "    \"\"\"Return the minimum positive number in the given list\"\"\"\n",
    "    positive_numbers = np.array(lst)[np.array(lst) > 0]\n",
    "\n",
    "    if len(positive_numbers) == 0:\n",
    "        return 0\n",
    "\n",
    "    min_positive = np.min(positive_numbers)\n",
    "    return min_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:41:40.198998Z",
     "start_time": "2024-03-18T02:41:38.324974Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 49879, expected 50000.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m     patient_freq_matrix \u001b[38;5;241m=\u001b[39m hstack(\n\u001b[1;32m     14\u001b[0m         [patient_freq_matrix, csr_matrix([num_visits, min_age, max_age])\u001b[38;5;241m.\u001b[39mT], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m patient_freq_matrix[:, \u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# Drop id feature\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m patient_freq_matrix \u001b[38;5;241m=\u001b[39m \u001b[43madd_age_to_freq_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_freq_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m patient_freq_matrix_test \u001b[38;5;241m=\u001b[39m add_age_to_freq_matrix(test_data, patient_freq_matrix_test)\n",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36madd_age_to_freq_matrix\u001b[0;34m(data, patient_freq_matrix)\u001b[0m\n\u001b[1;32m     10\u001b[0m max_age \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mmax(patient_age_tokens) \u001b[38;5;28;01mfor\u001b[39;00m patient_age_tokens \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage_tokens_2048\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Add extra features to the frequency dataset\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m patient_freq_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpatient_freq_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsr_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum_visits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_age\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_age\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m patient_freq_matrix[:, \u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m/fs01/home/afallah/light/lib/python3.10/site-packages/scipy/sparse/_construct.py:733\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _block([blocks], \u001b[38;5;28mformat\u001b[39m, dtype)\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 733\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_spmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/fs01/home/afallah/light/lib/python3.10/site-packages/scipy/sparse/_construct.py:948\u001b[0m, in \u001b[0;36m_block\u001b[0;34m(blocks, format, dtype, return_spmatrix)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m brow_lengths[i] \u001b[38;5;241m!=\u001b[39m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    945\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,:] has incompatible row dimensions. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    946\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot blocks[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m].shape[0] == \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    947\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbrow_lengths[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bcol_lengths[j] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    951\u001b[0m     bcol_lengths[j] \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 49879, expected 50000."
     ]
    }
   ],
   "source": [
    "# Get extra features such as number of visits and age\n",
    "def add_age_to_freq_matrix(data: pd.DataFrame, patient_freq_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Add age feature to patient frequency matrix. \"\"\"\n",
    "\n",
    "    num_visits = data[\"num_visits\"].values\n",
    "    min_age = [\n",
    "        find_min_greater_than_zero(patient_age_tokens)\n",
    "        for patient_age_tokens in data[\"age_tokens_2048\"]\n",
    "    ]\n",
    "    max_age = [np.max(patient_age_tokens) for patient_age_tokens in data[\"age_tokens_2048\"]]\n",
    "\n",
    "    # Add extra features to the frequency dataset\n",
    "    patient_freq_matrix = hstack(\n",
    "        [patient_freq_matrix, csr_matrix([num_visits, min_age, max_age]).T], format=\"csr\",\n",
    "    )\n",
    "    return patient_freq_matrix[:, 1:]  # Drop id feature\n",
    "\n",
    "patient_freq_matrix = add_age_to_freq_matrix(train_data, patient_freq_matrix)\n",
    "patient_freq_matrix_test = add_age_to_freq_matrix(test_data, patient_freq_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:41:40.227252Z",
     "start_time": "2024-03-18T02:41:40.200678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get intuition about the frequency of different features in the training dataset\n",
    "report_threshold = 1\n",
    "features_above_threshold = np.sum(\n",
    "    (patient_freq_matrix.getnnz(axis=0) >= report_threshold).astype(int),\n",
    ")\n",
    "\n",
    "print(f\"How many features have been reported for at least {report_threshold} patients?\\n\"\n",
    "      f\"{features_above_threshold} Features\")\n",
    "\n",
    "# Plot the histogram of feature frequency\n",
    "# plt.hist(patient_freq_matrix.getnnz(axis=0), bins=range(num_patients+1), edgecolor='black')\n",
    "# plt.xlabel('Number of Nonzero Rows')\n",
    "# plt.ylabel('Number of Columns')\n",
    "# plt.title('Histogram of Nonzero Rows per Column')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:41:40.255936Z",
     "start_time": "2024-03-18T02:41:40.228722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pick features to train the model on\n",
    "NUM_FEATURES = 20000\n",
    "features_sorted_by_freq = np.argsort(-patient_freq_matrix.getnnz(axis=0))\n",
    "selected_features = features_sorted_by_freq[: NUM_FEATURES + 1]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:41:40.261325Z",
     "start_time": "2024-03-18T02:41:40.258323Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define custom labels, here death in 12 M, not needed if dataset already has labels\n",
    "# data[\"label\"] = (\n",
    "#     (data[\"death_after_end\"] >= 0) & (data[\"death_after_end\"] <= 31)\n",
    "# ).astype(int)\n",
    "#\n",
    "# print(f\"Total positive labels: {sum(data['label'])} out of {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:41:42.023770Z",
     "start_time": "2024-03-18T02:41:41.994187Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data for model training\n",
    "X = vstack([patient_freq_matrix, patient_freq_matrix_test])\n",
    "Y = np.hstack([train_data[\"label\"].values, test_data[\"label\"].values])\n",
    "\n",
    "# Optional, Scale features. Didn't improve performance\n",
    "# scaler = MaxAbsScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# Optional, Split data into train and test sets if dataset is not already split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, Y, test_size=0.2, stratify=Y, random_state=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:41:42.557970Z",
     "start_time": "2024-03-18T02:41:42.551Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data into train and test based on original dataset definitions\n",
    "X_train = patient_freq_matrix\n",
    "X_test = patient_freq_matrix_test\n",
    "\n",
    "y_train = train_data[\"label\"].values\n",
    "y_test = test_data[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:41:47.279093Z",
     "start_time": "2024-03-18T02:41:42.845780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate class weights to scale positive weights\n",
    "total_negative = len(y_train) - sum(y_train)\n",
    "total_positive = sum(y_train)\n",
    "scale_pos_weight = total_negative / (total_positive // 1)    # 1.5 for two_weeks and 4 for one_month | use sqrt if extremely imbalanced\n",
    "\n",
    "# Single XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=23, scale_pos_weight=scale_pos_weight)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:41:48.274852Z",
     "start_time": "2024-03-18T02:41:47.281488Z"
    }
   },
   "outputs": [],
   "source": [
    "### ASSESS MODEL PERFORMANCE ###\n",
    "\n",
    "# Predict labels for train, test, and all data\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "y_train_prob = xgb_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "y_test_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "all_data_pred = xgb_model.predict(X)\n",
    "all_data_prob = xgb_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Balanced Accuracy\n",
    "y_train_accuracy = balanced_accuracy_score(y_train, y_train_pred)\n",
    "y_test_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "all_data_accuracy = balanced_accuracy_score(Y, all_data_pred)\n",
    "\n",
    "# F1 Score\n",
    "y_train_f1 = f1_score(y_train, y_train_pred)\n",
    "y_test_f1 = f1_score(y_test, y_test_pred)\n",
    "all_data_f1 = f1_score(Y, all_data_pred)\n",
    "\n",
    "# Precision\n",
    "y_train_precision = precision_score(y_train, y_train_pred)\n",
    "y_test_precision = precision_score(y_test, y_test_pred)\n",
    "all_data_precision = precision_score(Y, all_data_pred)\n",
    "\n",
    "# Recall\n",
    "y_train_recall = recall_score(y_train, y_train_pred)\n",
    "y_test_recall = recall_score(y_test, y_test_pred)\n",
    "all_data_recall = recall_score(Y, all_data_pred)\n",
    "\n",
    "# AUROC\n",
    "y_train_auroc = roc_auc_score(y_train, y_train_pred)\n",
    "y_test_auroc = roc_auc_score(y_test, y_test_pred)\n",
    "all_data_auroc = roc_auc_score(Y, all_data_pred)\n",
    "\n",
    "# AUC-PR (Area Under the Precision-Recall Curve)\n",
    "y_train_p, y_train_r, _ = precision_recall_curve(y_train, y_train_pred)\n",
    "y_test_p, y_test_r, _ = precision_recall_curve(y_test, y_test_pred)\n",
    "all_data_p, all_data_r, _ = precision_recall_curve(Y, all_data_pred)\n",
    "\n",
    "y_train_auc_pr = auc(y_train_r, y_train_p)\n",
    "y_test_auc_pr = auc(y_test_r, y_test_p)\n",
    "all_data_auc_pr = auc(all_data_r, all_data_p)\n",
    "\n",
    "# Average Precision Score (APS)\n",
    "y_train_aps = average_precision_score(y_train, y_train_pred)\n",
    "y_test_aps = average_precision_score(y_test, y_test_pred)\n",
    "all_data_aps = average_precision_score(Y, all_data_pred)\n",
    "\n",
    "# Print Metrics\n",
    "print(\n",
    "    f\"Balanced Accuracy\\nTrain: {y_train_accuracy:.5f}  |  Test: {y_test_accuracy:.5f}  |  All Data: {all_data_accuracy:.5f}\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"F1 Score\\nTrain: {y_train_f1:.5f}  |  Test: {y_test_f1:.5f}  |  All Data: {all_data_f1:.5f}\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Precision\\nTrain: {y_train_precision:.5f}  |  Test: {y_test_precision:.5f}  |  All Data: {all_data_precision:.5f}\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Recall\\nTrain: {y_train_recall:.5f}  |  Test: {y_test_recall:.5f}  |  All Data: {all_data_recall:.5f}\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"AUROC\\nTrain: {y_train_auroc:.5f}  |  Test: {y_test_auroc:.5f}  |  All Data: {all_data_auroc:.5f}\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"AUC-PR\\nTrain: {y_train_auc_pr:.5f}  |  Test: {y_test_auc_pr:.5f}  |  All Data: {all_data_auc_pr:.5f}\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Average Precision Score\\nTrain: {y_train_aps:.5f}  |  Test: {y_test_aps:.5f}  |  All Data: {all_data_aps:.5f}\\n\",\n",
    ")\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_prob)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)\n",
    "fpr_all_data, tpr_all_data, _ = roc_curve(Y, all_data_prob)\n",
    "\n",
    "# Plot Information\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr_train, tpr_train, label=f\"Train AUROC={y_train_auroc:.2f}\")\n",
    "plt.plot(fpr_test, tpr_test, label=f\"Test AUROC={y_test_auroc:.2f}\")\n",
    "plt.plot(fpr_all_data, tpr_all_data, label=f\"All Data AUROC={all_data_auroc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:43:37.750244Z",
     "start_time": "2024-03-18T02:43:37.449960Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgb_model, max_num_features=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T15:15:59.835420100Z",
     "start_time": "2024-03-13T15:15:59.795421400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CAREFUL, one needs to match feature ids to actual FHIR features before interpretation\n",
    "# Assess which features are the most important\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = xgb_model.feature_importances_\n",
    "\n",
    "# Create a list of tuples (feature, importance) and sort it by importance in descending order\n",
    "sorted_importances = sorted(zip(selected_features, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the top 10 most important features\n",
    "top_features = sorted_importances[:10]\n",
    "for feature, importance in top_features:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save current predictions, labels, and probabilities to disk\n",
    "np.save(f\"{ROOT}/xgboost_y_test_pred_two_weeks.npy\", y_test_pred)\n",
    "np.save(f\"{ROOT}/xgboost_y_test_pred_two_weeks_labels.npy\", y_test)\n",
    "np.save(f\"{ROOT}/xgboost_y_test_pred_two_weeks_prob.npy\", xgb_model.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### SCRIPT FOR K-FOLD VALIDATION ###\n",
    "N_FOLDS = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "stratified_kfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=23)\n",
    "\n",
    "# Initialize lists to store performance metrics for each fold\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "aurocs = []\n",
    "auc_prs = []\n",
    "average_precision_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in tqdm(\n",
    "        stratified_kfold.split(X, Y),\n",
    "        desc=f\"{N_FOLDS}-Fold Validation\",\n",
    "        unit=\" Model(s)\",\n",
    "):\n",
    "    # Get the relevant train and test data\n",
    "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_test_fold = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Create a new XGBoost model for each fold\n",
    "    xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=23, scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "    # Train the model on the training fold\n",
    "    xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predict on the test fold\n",
    "    y_pred_fold = xgb_model.predict(X_test_fold)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    accuracy_fold = balanced_accuracy_score(y_test_fold, y_pred_fold)\n",
    "    f1_fold = f1_score(y_test_fold, y_pred_fold)\n",
    "    precision_fold = precision_score(y_test_fold, y_pred_fold)\n",
    "    recall_fold = recall_score(y_test_fold, y_pred_fold)\n",
    "    auroc_fold = roc_auc_score(y_test_fold, y_pred_fold)\n",
    "    p_fold, r_fold, _ = precision_recall_curve(y_test_fold, y_pred_fold)\n",
    "    auc_pr_fold = auc(r_fold, p_fold)\n",
    "    average_precision_score_fold = average_precision_score(y_test_fold, y_pred_fold)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "    f1_scores.append(f1_fold)\n",
    "    precisions.append(precision_fold)\n",
    "    recalls.append(recall_fold)\n",
    "    aurocs.append(auroc_fold)\n",
    "    auc_prs.append(auc_pr_fold)\n",
    "    average_precision_scores.append(average_precision_score_fold)\n",
    "\n",
    "# Print average metrics across all folds\n",
    "print(f\"Average Balanced Accuracy: {sum(accuracy_scores) / N_FOLDS:.5f}\")\n",
    "print(f\"Average F1 Score: {sum(f1_scores) / N_FOLDS:.5f}\")\n",
    "print(f\"Average Precision: {sum(precisions) / N_FOLDS:.5f}\")\n",
    "print(f\"Average Recall: {sum(recalls) / N_FOLDS:.5f}\")\n",
    "print(f\"Average AUROC: {sum(aurocs) / N_FOLDS:.5f}\")\n",
    "print(f\"Average AUC-PR: {sum(auc_prs) / N_FOLDS:.5f}\")\n",
    "print(f\"Average Precision Score: {sum(average_precision_scores) / N_FOLDS:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Generate labels for the dataset if necessary\n",
    "# labes_for_given_token = []; given_token = '8135'; de = []\n",
    "#\n",
    "# for idx, patient in tqdm(dataset.iterrows(), desc=\"Loading Tokens\", unit=\" Patients\"):\n",
    "#     if given_token in list(patient['event_tokens_2048'].split(' ')):\n",
    "#         # print(patient); break\n",
    "#         de.append(patient['label'])\n",
    "#\n",
    "# print(f\"Total Occurrences: {len(labes_for_given_token)}, Positive Labels: {sum(labes_for_given_token)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
