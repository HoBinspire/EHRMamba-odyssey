{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:09:25.027764400Z",
     "start_time": "2024-01-24T16:09:25.021696500Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: Bi-LSTM.ipynb\n",
    "Code to train and evaluate a bi-directional LSTM model on MIMIC-IV FHIR dataset.\n",
    "\"\"\"\n",
    "\n",
    "def Project():\n",
    "    \"\"\"\n",
    "    __Objectives__\n",
    "    0. Import data and tokenizer\n",
    "    1. Train the tokenizer on all sequences of the dataset\n",
    "    2. Tokenize different sequences and join them together\n",
    "    >>> 3. Prepare actual labels for one, six, twelve month death after discharge\n",
    "    >>> 4. Define the model architecture for bidrectional LSTM\n",
    "    >>> 5. Train Bi-LSTM model and evaluate on test dataset\n",
    "    >>> 6. Compare performance across new tasks to XGBoost\n",
    "\n",
    "    __Questions__\n",
    "    0.\n",
    "\n",
    "    __Extra__\n",
    "    Careful with tokenizing all sequences as it could tricky!\n",
    "\n",
    "    \"\"\"\n",
    "    return ProjectObjectives.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adibv\\.conda\\envs\\light\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import os; ROOT = 'E:\\Vector Institute\\odyssey'; os.chdir(ROOT)\n",
    "import scipy, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, precision_recall_curve, roc_auc_score, average_precision_score\n",
    "from scipy.sparse import csr_matrix, hstack, vstack, save_npz, load_npz\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import relu, leaky_relu, sigmoid\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from models.cehr_bert.data import PretrainDataset, FinetuneDataset\n",
    "from models.cehr_bert.model import BertPretrain\n",
    "from models.cehr_bert.tokenizer import ConceptTokenizer\n",
    "from models.cehr_bert.embeddings import Embeddings\n",
    "\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_ROOT = f'{ROOT}/data'\n",
    "DATA_PATH = f'{DATA_ROOT}/patient_sequences.parquet'\n",
    "SAMPLE_DATA_PATH = f'{DATA_ROOT}/CEHR-BERT_sample_patient_sequence.parquet'\n",
    "FREQ_DF_PATH = f'{DATA_ROOT}/patient_feature_freq.csv'\n",
    "FREQ_MATRIX_PATH = f'{DATA_ROOT}/patient_freq_matrix.npz'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:09:33.872821900Z",
     "start_time": "2024-01-24T16:09:25.030761500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'NVIDIA GeForce GTX 1650 Ti'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save parameters and configurations\n",
    "class config:\n",
    "    seed = 23\n",
    "    data_dir = DATA_ROOT\n",
    "    test_size = 0.2\n",
    "    max_len = 500\n",
    "    batch_size = 8\n",
    "    num_workers = 2\n",
    "    vocab_size = None\n",
    "    embedding_size = 128\n",
    "    time_embeddings_size = 16\n",
    "    max_seq_length = 512\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "def seed_all(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # pl.seed_everything(seed)\n",
    "\n",
    "seed_all(config.seed)\n",
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:09:33.909375100Z",
     "start_time": "2024-01-24T16:09:33.877821500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 patient_id  num_visits  label  \\\n0      be7990af-3829-5df0-b552-c397a71d46fe           3      0   \n1      877d281b-676b-53ab-9911-1e4677989f6f           1      0   \n2      65ae1ba2-dede-53a4-80be-3d0666b27e87           1      0   \n3      aa1446f6-dbc4-5734-9645-a1e01a7ba6f0           1      0   \n4      b3c303cc-df8c-5789-80f0-83f1c319b813           1      1   \n...                                     ...         ...    ...   \n90273  88ae054e-0173-5049-b067-a67bad1aeee9           1      0   \n90274  3b6ec88d-59a8-5833-8977-48e8b58211b1           1      0   \n90275  b883470b-664e-5f0e-b38c-717cd5b07b84           1      1   \n90277  c946654b-2765-5dc1-8cd4-9865d3c84d30           2      0   \n90278  fd4c2513-8fb6-56f3-b142-009e3d0f520f           1      0   \n\n       death_after_start  death_after_end  length  token_length  new_start  \\\n0                    NaN              NaN     217           225        NaN   \n1                    NaN              NaN      18            20        NaN   \n2                    NaN              NaN      40            42        NaN   \n3                    NaN              NaN      18            20        NaN   \n4                   22.0             17.0      81            83        NaN   \n...                  ...              ...     ...           ...        ...   \n90273                NaN              NaN      36            38        NaN   \n90274                NaN              NaN      17            19        NaN   \n90275                3.0              0.0     152           154        NaN   \n90277                NaN              NaN      46            51        NaN   \n90278                NaN              NaN      76            78        NaN   \n\n                                event_tokens_untruncated  \\\n0      [VS, 4443, 00338004304, 00006473900, 000935211...   \n1      [VS, 741, 00182864389, 00904585461, 0070345020...   \n2      [VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...   \n3      [VS, 0689, 33332000801, 00056017075, 655970103...   \n4      [VS, 7935, 00338067104, 00054855324, 009045165...   \n...                                                  ...   \n90273  [VS, 7931, 00075062041, 00023050601, 005363381...   \n90274  [VS, 00338067104, 51079045620, 66553000401, 00...   \n90275  [VS, 5503, 00338004904, 00006494300, 001828447...   \n90277  [VS, 51079088120, 51079088120, 68084025401, 00...   \n90278  [VS, 8151, 0077, 00574705050, 00904516561, 003...   \n\n                                            event_tokens  \\\n0      [VS, 4443, 00338004304, 00006473900, 000935211...   \n1      [VS, 741, 00182864389, 00904585461, 0070345020...   \n2      [VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...   \n3      [VS, 0689, 33332000801, 00056017075, 655970103...   \n4      [VS, 7935, 00338067104, 00054855324, 009045165...   \n...                                                  ...   \n90273  [VS, 7931, 00075062041, 00023050601, 005363381...   \n90274  [VS, 00338067104, 51079045620, 66553000401, 00...   \n90275  [VS, 5503, 00338004904, 00006494300, 001828447...   \n90277  [VS, 51079088120, 51079088120, 68084025401, 00...   \n90278  [VS, 8151, 0077, 00574705050, 00904516561, 003...   \n\n                                              age_tokens  \\\n0      [66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 6...   \n1      [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 3...   \n2      [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2...   \n3      [77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 7...   \n4      [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 6...   \n...                                                  ...   \n90273  [32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 3...   \n90274  [68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 6...   \n90275  [81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 8...   \n90277  [45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 4...   \n90278  [68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 6...   \n\n                                             time_tokens  \\\n0      [8000, 8000, 8000, 8000, 8000, 8000, 8000, 800...   \n1      [5085, 5085, 5085, 5085, 5085, 5085, 5085, 508...   \n2      [8787, 8787, 8787, 8787, 8787, 8787, 8787, 878...   \n3      [4853, 4853, 4853, 4853, 4853, 4853, 4853, 485...   \n4      [6037, 6037, 6037, 6037, 6037, 6037, 6037, 603...   \n...                                                  ...   \n90273  [8788, 8788, 8788, 8788, 8788, 8788, 8788, 878...   \n90274  [5353, 5353, 5353, 5353, 5353, 5353, 5353, 535...   \n90275  [7450, 7450, 7450, 7450, 7450, 7450, 7450, 745...   \n90277  [4850, 4850, 4850, 4850, 4850, 4850, 4850, 485...   \n90278  [8480, 8480, 8480, 8480, 8480, 8480, 8480, 848...   \n\n                                            visit_tokens  \\\n0      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n1      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n2      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n3      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n4      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n...                                                  ...   \n90273  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n90274  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n90275  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n90277  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n90278  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n\n                                         position_tokens  \n0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n...                                                  ...  \n90273  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n90274  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n90275  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n90277  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n90278  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n\n[173671 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>num_visits</th>\n      <th>label</th>\n      <th>death_after_start</th>\n      <th>death_after_end</th>\n      <th>length</th>\n      <th>token_length</th>\n      <th>new_start</th>\n      <th>event_tokens_untruncated</th>\n      <th>event_tokens</th>\n      <th>age_tokens</th>\n      <th>time_tokens</th>\n      <th>visit_tokens</th>\n      <th>position_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>be7990af-3829-5df0-b552-c397a71d46fe</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>217</td>\n      <td>225</td>\n      <td>NaN</td>\n      <td>[VS, 4443, 00338004304, 00006473900, 000935211...</td>\n      <td>[VS, 4443, 00338004304, 00006473900, 000935211...</td>\n      <td>[66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 6...</td>\n      <td>[8000, 8000, 8000, 8000, 8000, 8000, 8000, 800...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>877d281b-676b-53ab-9911-1e4677989f6f</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>[VS, 741, 00182864389, 00904585461, 0070345020...</td>\n      <td>[VS, 741, 00182864389, 00904585461, 0070345020...</td>\n      <td>[37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 3...</td>\n      <td>[5085, 5085, 5085, 5085, 5085, 5085, 5085, 508...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65ae1ba2-dede-53a4-80be-3d0666b27e87</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n      <td>42</td>\n      <td>NaN</td>\n      <td>[VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...</td>\n      <td>[VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...</td>\n      <td>[24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2...</td>\n      <td>[8787, 8787, 8787, 8787, 8787, 8787, 8787, 878...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aa1446f6-dbc4-5734-9645-a1e01a7ba6f0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>[VS, 0689, 33332000801, 00056017075, 655970103...</td>\n      <td>[VS, 0689, 33332000801, 00056017075, 655970103...</td>\n      <td>[77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 7...</td>\n      <td>[4853, 4853, 4853, 4853, 4853, 4853, 4853, 485...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b3c303cc-df8c-5789-80f0-83f1c319b813</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>17.0</td>\n      <td>81</td>\n      <td>83</td>\n      <td>NaN</td>\n      <td>[VS, 7935, 00338067104, 00054855324, 009045165...</td>\n      <td>[VS, 7935, 00338067104, 00054855324, 009045165...</td>\n      <td>[62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 6...</td>\n      <td>[6037, 6037, 6037, 6037, 6037, 6037, 6037, 603...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90273</th>\n      <td>88ae054e-0173-5049-b067-a67bad1aeee9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>36</td>\n      <td>38</td>\n      <td>NaN</td>\n      <td>[VS, 7931, 00075062041, 00023050601, 005363381...</td>\n      <td>[VS, 7931, 00075062041, 00023050601, 005363381...</td>\n      <td>[32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 3...</td>\n      <td>[8788, 8788, 8788, 8788, 8788, 8788, 8788, 878...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>90274</th>\n      <td>3b6ec88d-59a8-5833-8977-48e8b58211b1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17</td>\n      <td>19</td>\n      <td>NaN</td>\n      <td>[VS, 00338067104, 51079045620, 66553000401, 00...</td>\n      <td>[VS, 00338067104, 51079045620, 66553000401, 00...</td>\n      <td>[68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 6...</td>\n      <td>[5353, 5353, 5353, 5353, 5353, 5353, 5353, 535...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>90275</th>\n      <td>b883470b-664e-5f0e-b38c-717cd5b07b84</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>152</td>\n      <td>154</td>\n      <td>NaN</td>\n      <td>[VS, 5503, 00338004904, 00006494300, 001828447...</td>\n      <td>[VS, 5503, 00338004904, 00006494300, 001828447...</td>\n      <td>[81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 8...</td>\n      <td>[7450, 7450, 7450, 7450, 7450, 7450, 7450, 745...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>90277</th>\n      <td>c946654b-2765-5dc1-8cd4-9865d3c84d30</td>\n      <td>2</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>46</td>\n      <td>51</td>\n      <td>NaN</td>\n      <td>[VS, 51079088120, 51079088120, 68084025401, 00...</td>\n      <td>[VS, 51079088120, 51079088120, 68084025401, 00...</td>\n      <td>[45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 4...</td>\n      <td>[4850, 4850, 4850, 4850, 4850, 4850, 4850, 485...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>90278</th>\n      <td>fd4c2513-8fb6-56f3-b142-009e3d0f520f</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>76</td>\n      <td>78</td>\n      <td>NaN</td>\n      <td>[VS, 8151, 0077, 00574705050, 00904516561, 003...</td>\n      <td>[VS, 8151, 0077, 00574705050, 00904516561, 003...</td>\n      <td>[68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 6...</td>\n      <td>[8480, 8480, 8480, 8480, 8480, 8480, 8480, 848...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>173671 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_parquet(DATA_PATH)\n",
    "data.rename(columns={'event_tokens': 'event_tokens_untruncated', 'event_tokens_updated': 'event_tokens'}, inplace=True)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:09:46.893999300Z",
     "start_time": "2024-01-24T16:09:33.908374800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define custom labels, here death in 12 M\n",
    "data['label'] = ((data['death_after_end'] > 0) & (data['death_after_end'] < 365)).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:09:46.901669300Z",
     "start_time": "2024-01-24T16:09:46.896999700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<models.cehr_bert.tokenizer.ConceptTokenizer at 0x1c337e71f10>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit tokenizer on .json vocab files\n",
    "tokenizer = ConceptTokenizer(data_dir=config.data_dir)\n",
    "tokenizer.fit_on_vocab()\n",
    "config.vocab_size = tokenizer.get_vocab_size()\n",
    "tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:09:47.035228900Z",
     "start_time": "2024-01-24T16:09:46.903670500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "                               patient_id  num_visits  label  \\\n0    be7990af-3829-5df0-b552-c397a71d46fe           3      0   \n1    877d281b-676b-53ab-9911-1e4677989f6f           1      0   \n2    65ae1ba2-dede-53a4-80be-3d0666b27e87           1      0   \n3    aa1446f6-dbc4-5734-9645-a1e01a7ba6f0           1      0   \n4    b3c303cc-df8c-5789-80f0-83f1c319b813           1      1   \n..                                    ...         ...    ...   \n101  79740e0e-6da1-5483-bf25-225354e249cc           3      0   \n102  e7cc1bc6-9e86-54b2-9d00-e23eae8d4459           1      0   \n103  c1c54a3d-43e7-5e63-841a-c349708a548d           3      0   \n104  1a52e3fa-4453-5cc7-b50d-c9276032b6bd           1      0   \n105  bbdafd18-6dfb-5ea1-bca4-1731fe7bd6cd           2      0   \n\n     death_after_start  death_after_end  length  token_length  new_start  \\\n0                  NaN              NaN     217           225        NaN   \n1                  NaN              NaN      18            20        NaN   \n2                  NaN              NaN      40            42        NaN   \n3                  NaN              NaN      18            20        NaN   \n4                 22.0             17.0      81            83        NaN   \n..                 ...              ...     ...           ...        ...   \n101                NaN              NaN    1198          1206      695.0   \n102                NaN              NaN      53            55        NaN   \n103                NaN              NaN     245           253        NaN   \n104                NaN              NaN     598           600       89.0   \n105                NaN              NaN      66            71        NaN   \n\n                              event_tokens_untruncated  \\\n0    [VS, 4443, 00338004304, 00006473900, 000935211...   \n1    [VS, 741, 00182864389, 00904585461, 0070345020...   \n2    [VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...   \n3    [VS, 0689, 33332000801, 00056017075, 655970103...   \n4    [VS, 7935, 00338067104, 00054855324, 009045165...   \n..                                                 ...   \n101  [VS, 0DBN0ZZ, 0D1M0Z4, 0D1M0Z4, 0DN80ZZ, 00338...   \n102  [VS, 00781305714, 00406055262, 33332001101, 51...   \n103  [VS, 00904224461, 00182844789, 00074568113, 00...   \n104  [VS, 009U3ZX, 00904198861, 49999002812, 003784...   \n105  [VS, 00182845389, 58160087546, 00406055262, 63...   \n\n                                          event_tokens  \\\n0    [VS, 4443, 00338004304, 00006473900, 000935211...   \n1    [VS, 741, 00182864389, 00904585461, 0070345020...   \n2    [VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...   \n3    [VS, 0689, 33332000801, 00056017075, 655970103...   \n4    [VS, 7935, 00338067104, 00054855324, 009045165...   \n..                                                 ...   \n101  [VS, 51237_3, 51274_3, 51275_4, 50868_1, 50882...   \n102  [VS, 00781305714, 00406055262, 33332001101, 51...   \n103  [VS, 00904224461, 00182844789, 00074568113, 00...   \n104  [VS, 50960_0, 50931_0, 50912_4, 50902_0, 50893...   \n105  [VS, 00182845389, 58160087546, 00406055262, 63...   \n\n                                            age_tokens  \\\n0    [66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 6...   \n1    [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 3...   \n2    [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2...   \n3    [77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 7...   \n4    [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 6...   \n..                                                 ...   \n101  [78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 7...   \n102  [56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 5...   \n103  [83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 8...   \n104  [43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...   \n105  [88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 8...   \n\n                                           time_tokens  \\\n0    [8000, 8000, 8000, 8000, 8000, 8000, 8000, 800...   \n1    [5085, 5085, 5085, 5085, 5085, 5085, 5085, 508...   \n2    [8787, 8787, 8787, 8787, 8787, 8787, 8787, 878...   \n3    [4853, 4853, 4853, 4853, 4853, 4853, 4853, 485...   \n4    [6037, 6037, 6037, 6037, 6037, 6037, 6037, 603...   \n..                                                 ...   \n101  [7066, 7066, 7066, 7066, 7066, 7066, 7066, 706...   \n102  [8704, 8704, 8704, 8704, 8704, 8704, 8704, 870...   \n103  [7519, 7519, 7519, 7519, 7519, 7519, 7519, 751...   \n104  [7153, 7153, 7153, 7153, 7153, 7153, 7153, 715...   \n105  [8086, 8086, 8086, 8086, 8086, 8086, 8086, 808...   \n\n                                          visit_tokens  \\\n0    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n1    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n2    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n3    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n4    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n..                                                 ...   \n101  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n102  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n103  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n104  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n105  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n\n                                       position_tokens  \n0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n..                                                 ...  \n101  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n102  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n103  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n104  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n105  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n\n[100 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>num_visits</th>\n      <th>label</th>\n      <th>death_after_start</th>\n      <th>death_after_end</th>\n      <th>length</th>\n      <th>token_length</th>\n      <th>new_start</th>\n      <th>event_tokens_untruncated</th>\n      <th>event_tokens</th>\n      <th>age_tokens</th>\n      <th>time_tokens</th>\n      <th>visit_tokens</th>\n      <th>position_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>be7990af-3829-5df0-b552-c397a71d46fe</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>217</td>\n      <td>225</td>\n      <td>NaN</td>\n      <td>[VS, 4443, 00338004304, 00006473900, 000935211...</td>\n      <td>[VS, 4443, 00338004304, 00006473900, 000935211...</td>\n      <td>[66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 6...</td>\n      <td>[8000, 8000, 8000, 8000, 8000, 8000, 8000, 800...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>877d281b-676b-53ab-9911-1e4677989f6f</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>[VS, 741, 00182864389, 00904585461, 0070345020...</td>\n      <td>[VS, 741, 00182864389, 00904585461, 0070345020...</td>\n      <td>[37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 3...</td>\n      <td>[5085, 5085, 5085, 5085, 5085, 5085, 5085, 508...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65ae1ba2-dede-53a4-80be-3d0666b27e87</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n      <td>42</td>\n      <td>NaN</td>\n      <td>[VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...</td>\n      <td>[VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...</td>\n      <td>[24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2...</td>\n      <td>[8787, 8787, 8787, 8787, 8787, 8787, 8787, 878...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aa1446f6-dbc4-5734-9645-a1e01a7ba6f0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>[VS, 0689, 33332000801, 00056017075, 655970103...</td>\n      <td>[VS, 0689, 33332000801, 00056017075, 655970103...</td>\n      <td>[77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 7...</td>\n      <td>[4853, 4853, 4853, 4853, 4853, 4853, 4853, 485...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b3c303cc-df8c-5789-80f0-83f1c319b813</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>17.0</td>\n      <td>81</td>\n      <td>83</td>\n      <td>NaN</td>\n      <td>[VS, 7935, 00338067104, 00054855324, 009045165...</td>\n      <td>[VS, 7935, 00338067104, 00054855324, 009045165...</td>\n      <td>[62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 6...</td>\n      <td>[6037, 6037, 6037, 6037, 6037, 6037, 6037, 603...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>79740e0e-6da1-5483-bf25-225354e249cc</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1198</td>\n      <td>1206</td>\n      <td>695.0</td>\n      <td>[VS, 0DBN0ZZ, 0D1M0Z4, 0D1M0Z4, 0DN80ZZ, 00338...</td>\n      <td>[VS, 51237_3, 51274_3, 51275_4, 50868_1, 50882...</td>\n      <td>[78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 7...</td>\n      <td>[7066, 7066, 7066, 7066, 7066, 7066, 7066, 706...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>e7cc1bc6-9e86-54b2-9d00-e23eae8d4459</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>53</td>\n      <td>55</td>\n      <td>NaN</td>\n      <td>[VS, 00781305714, 00406055262, 33332001101, 51...</td>\n      <td>[VS, 00781305714, 00406055262, 33332001101, 51...</td>\n      <td>[56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 5...</td>\n      <td>[8704, 8704, 8704, 8704, 8704, 8704, 8704, 870...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>c1c54a3d-43e7-5e63-841a-c349708a548d</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>245</td>\n      <td>253</td>\n      <td>NaN</td>\n      <td>[VS, 00904224461, 00182844789, 00074568113, 00...</td>\n      <td>[VS, 00904224461, 00182844789, 00074568113, 00...</td>\n      <td>[83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 8...</td>\n      <td>[7519, 7519, 7519, 7519, 7519, 7519, 7519, 751...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>1a52e3fa-4453-5cc7-b50d-c9276032b6bd</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>598</td>\n      <td>600</td>\n      <td>89.0</td>\n      <td>[VS, 009U3ZX, 00904198861, 49999002812, 003784...</td>\n      <td>[VS, 50960_0, 50931_0, 50912_4, 50902_0, 50893...</td>\n      <td>[43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...</td>\n      <td>[7153, 7153, 7153, 7153, 7153, 7153, 7153, 715...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>bbdafd18-6dfb-5ea1-bca4-1731fe7bd6cd</td>\n      <td>2</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>66</td>\n      <td>71</td>\n      <td>NaN</td>\n      <td>[VS, 00182845389, 58160087546, 00406055262, 63...</td>\n      <td>[VS, 00182845389, 58160087546, 00406055262, 63...</td>\n      <td>[88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 8...</td>\n      <td>[8086, 8086, 8086, 8086, 8086, 8086, 8086, 808...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get training and test datasets\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "            data[:100],\n",
    "            test_size=config.test_size,\n",
    "            random_state=config.seed,\n",
    "            stratify=data['label'][:100]\n",
    ")\n",
    "\n",
    "train_dataset = FinetuneDataset(\n",
    "        data=train_data,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=config.max_len,\n",
    ")\n",
    "\n",
    "test_dataset = FinetuneDataset(\n",
    "        data=test_data,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=config.max_len,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:42:39.861030700Z",
     "start_time": "2024-01-24T16:42:39.805753600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "\n",
    "class BiLSTMModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_size, num_layers, output_size, dropout_rate=0.5):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "\n",
    "        self.embeddings = Embeddings(\n",
    "            vocab_size=config.vocab_size,\n",
    "            embedding_size=config.embedding_size,\n",
    "            time_embedding_size=config.time_embeddings_size,\n",
    "            max_len=config.max_seq_length)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True,\n",
    "                            dropout=dropout_rate)\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size * 2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear1 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.embeddings(*inputs)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = lstm_out[:, -1, :]\n",
    "        output = self.batch_norm(output)\n",
    "        output = self.dropout(output)\n",
    "        output = relu(self.linear1(output))\n",
    "        output = self.linear2(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_inputs_labels(batch):\n",
    "        labels = batch['labels'].view(-1, 1).to(config.device)\n",
    "        inputs = batch['concept_ids'].to(config.device),\\\n",
    "                 batch['time_stamps'].to(config.device),\\\n",
    "                 batch['ages'].to(config.device),\\\n",
    "                 batch['visit_orders'].to(config.device),\\\n",
    "                 batch['visit_segments'].to(config.device)\n",
    "\n",
    "        return inputs, labels.float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:32:23.484320800Z",
     "start_time": "2024-01-24T16:32:23.459890600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Set hyperparameters for Bi-LSTM model adn training loop\n",
    "input_size = config.embedding_size              # embedding_dim\n",
    "hidden_size = config.embedding_size             # output hidden size\n",
    "num_layers = 5                                  # number of LSTM layers\n",
    "output_size = 1                                 # Binary classification, so output size is 1\n",
    "dropout_rate = 0.5                              # Dropout rate for regularization\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 0.002"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:32:23.778227500Z",
     "start_time": "2024-01-24T16:32:23.764247700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "({'concept_ids': tensor([    1,  5116,  5975,  4757,  6787,  4757,  2980,  5975,  1743,  2566,\n            542,  2909,  2329,   634,  1753,  1204,   433,   188,  1625,   722,\n            896,   135,   379,  1711,  1571,  2786,  1640,   742,   605,  2882,\n              1, 20586,     1,  6269,  4726,  3688,  5428,  4450,  3494,  5975,\n           3639,  5715,  6889,  3345,  5369,  5255,  4450,  5979,  3529,  4944,\n           2980,  4651,  1352,  2369,  1069,    56,   722,   865,   896,   390,\n           1261,  1711,  1571,  1990,  1749,   891,   605,   196,   866,  2174,\n           1064,  1804,  1976,   105,   245,  2666,  1905,   188,   134,  2912,\n           2592,   379,  1711,  1571,  1749,  1442,   891,  1131,  1905,   188,\n            685,  2230,  1198,  1064,  1804,  2132,   105,   245,  1204,  2268,\n           1428,  1601,  1348,   896,  1716,   379,  1711,   480,  1749,  2234,\n           1725,   605,   196,  2230,  2174,  1064,  1804,  2132,   105,   245,\n           1204,     1, 20579,     1,  7109,  4498,  7109,  7704,  7109,  3529,\n           5369,  5979,  7704,  5428,  5876,  2980,  7209,  7704,  4183,  5979,\n           1352,  2322,  2321,   865,  2584,  1369,  1716,   379,  1711,   269,\n            458,  1442,  1725,   355,   196,  2264,  1323,  1064,  1804,  1976,\n            645,   864,  2517,  2303,   866,  2174,  1064,  1804,  1976,   645,\n           1810,  1204,   722,   965,  2592,   379,  1711,   269,  1749,  1442,\n            891,  1131,   196,     1, 20574,     1,  5979,  6151,  5369,  3529,\n           2980,  5441,  5715,  5777,  4944,  1905,   188,  2861,  2264,  1323,\n           1064,  2909,  1657,   645,   864,  1204,   134,   896,   379,  1711,\n            480,  1895,   605,  1639,     1, 20579,     1, 13801,  4292,  3345,\n           3529,  3573,  3688,  5303,  5020,  5715,  4362,  4726,  5173,  3573,\n           3009,  3345,  5370,  5715,  5098,  5098,  3345,  7157,  3853,  6151,\n           5173,  6423,  4498,  5098,  5612,  4582,  4944,  3345,  6423,  7704,\n           4944,  3952,  4498,  5734,  5369,  3952,  7704,  3978,   602,  2225,\n           1827,  1877,  1815,  1452,   808,   685,   722,   965,  2592,   379,\n           1711,   269,   458,  1686,   891,   605,  2882,  2523,  1137,  1007,\n           2230,  1198,   501,   978,  1971,  1953,  1372,  1976,   105,  1810,\n           2007,   131,  1800,  2429,  2102,  1544,   866,  2174,  2321,  2584,\n           2592,  2179,  1711,   269,  1749,  1640,  1725,  1131,   196,  1452,\n           2494,  2861,  2230,  1198,   978,  1971,  1976,   105,  1810,  2007,\n           2230,  1198,   978,  1971,  2132,   105,  1810,  2007,   722,   896,\n           2100,   379,  1711,   269,   551,  2234,  1895,  1131,   196,     1,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569, 20569,\n          20569, 20569], dtype=torch.int32),\n  'ages': tensor([47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,  0, 47, 47, 47, 47,\n          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48,  0, 48, 48, 48,\n          48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n          48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n          48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n          48, 48, 48, 48,  0, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n          48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,  0,\n          48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n          48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n          48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n          48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n          48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n          48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n          48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n           0,  0,  0,  0,  0,  0,  0,  0]),\n  'time_stamps': tensor([6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644,\n          6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644,\n          6644, 6644, 6644, 6644, 6644, 6644, 6644,    0, 6644, 6644, 6644, 6644,\n          6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644,\n          6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644,\n          6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644,\n          6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644,\n          6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644,\n          6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644,\n          6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644, 6644,\n          6644, 6697,    0, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697,    0, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,    0,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697, 6697,\n          6697, 6697, 6697, 6697,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0]),\n  'visit_orders': tensor([  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n            1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n            1,   1,   1,   1,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n            2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n            2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n            2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n            2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n            2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n            2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   3,   3,   3,\n            3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n            3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n            3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n            3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n            3,   3,   3,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n            4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n            4,   4,   4,   4,   4,   4,   5,   5,   5,   5,   5,   5,   5,   5,\n            5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n            5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n            5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n            5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n            5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n            5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n            5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n            5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n            5,   5,   5,   5, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513, 513,\n          513, 513, 513, 513, 513, 513, 513, 513]),\n  'visit_segments': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]),\n  'labels': tensor(1, dtype=torch.int32),\n  'attention_mask': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n          0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.])},\n 340)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Loop\n",
    "model = BiLSTMModel(input_size, hidden_size, num_layers, output_size, dropout_rate).to(config.device)\n",
    "loss_fcn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.8, verbose=True)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_total_loss = 0; train_accuracy = 0; test_accuracy = 0\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    for batch_no, batch in tqdm(enumerate(train_loader),\n",
    "                                total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}', unit=' batch'):\n",
    "\n",
    "        inputs, labels = model.get_inputs_labels(batch)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fcn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_total_loss += loss.item()\n",
    "        # print(f'Batch Loss: {loss.item():.4f}', end='\\r')\n",
    "\n",
    "\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     for batch_no, batch in tqdm(enumerate(train_loader),\n",
    "    #                                 total=len(train_loader), desc=f'Train Evaluation {epoch+1}/{epochs}', unit=' batch'):\n",
    "    #\n",
    "    #         inputs, labels = model.get_inputs_labels(batch)\n",
    "    #         outputs = model(inputs)\n",
    "    #         predictions = torch.round(sigmoid(outputs))\n",
    "    #         train_accuracy += balanced_accuracy_score(labels, predictions)\n",
    "    #\n",
    "    #\n",
    "    #     for batch_no, batch in tqdm(enumerate(test_loader),\n",
    "    #                                 total=len(test_loader), desc=f'Test Evaluation {epoch+1}/{epochs}', unit=' batch'):\n",
    "    #\n",
    "    #         inputs, labels = model.get_inputs_labels(batch)\n",
    "    #         outputs = model(inputs)\n",
    "    #         predictions = torch.round(sigmoid(outputs))\n",
    "    #         test_accuracy += balanced_accuracy_score(labels, predictions)\n",
    "\n",
    "\n",
    "    print(f'Average Train Loss: {train_total_loss/len(train_loader):.5f}  |  Last Batch Train Loss: {loss.item()}  |  '\n",
    "          f'Train Accuracy: {train_accuracy/len(train_loader)}  |  Test Accuracy: {test_accuracy/len(test_loader)}')\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:32:32.429809100Z",
     "start_time": "2024-01-24T16:32:32.402757300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetWithTokenLength' object has no attribute 'sort'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_dataset_with_lengths\u001B[38;5;241m.\u001B[39msort()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'DatasetWithTokenLength' object has no attribute 'sort'"
     ]
    }
   ],
   "source": [
    "# jupyter\n",
    "# reevaluate xgboost with new label and send it github"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:11:41.430607400Z",
     "start_time": "2024-01-24T16:11:39.359038900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
