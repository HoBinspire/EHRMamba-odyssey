{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: Bi-LSTM.ipynb\n",
    "Code to train and evaluate a bi-directional LSTM model on MIMIC-IV FHIR dataset.\n",
    "\"\"\"\n",
    "\n",
    "def Project():\n",
    "    \"\"\"\n",
    "    __Objectives__\n",
    "    >>> 0. Import data and tokenizer\n",
    "    >>> 1. Train the tokenizer on all sequences of the dataset\n",
    "    >>> 2. Tokenize different sequences and join them together\n",
    "    >>> 3. Prepare actual labels for one, six, twelve month death after discharge\n",
    "    >>> 4. Define the model architecture for bidrectional LSTM\n",
    "    >>> 5. Train Bi-LSTM model and evaluate on test dataset\n",
    "    >>> 6. Compare performance across new tasks to XGBoost\n",
    "\n",
    "    __Questions__\n",
    "    0.\n",
    "\n",
    "    __Extra__\n",
    "    Careful with tokenizing all sequences as it could tricky!\n",
    "\n",
    "    \"\"\"\n",
    "    return ProjectObjectives.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ROOT = 'E:\\Vector Institute\\odyssey'\n",
    "import os; os.chdir(ROOT)\n",
    "import scipy, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, precision_recall_curve, roc_auc_score, average_precision_score\n",
    "from scipy.sparse import csr_matrix, hstack, vstack, save_npz, load_npz\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import relu, leaky_relu\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "from models.cehr_bert.data import PretrainDataset, FinetuneDataset\n",
    "from models.cehr_bert.model import BertPretrain\n",
    "from models.cehr_bert.tokenizer import ConceptTokenizer\n",
    "from models.cehr_bert.embeddings import Embeddings\n",
    "\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_ROOT = f'{ROOT}/data'\n",
    "DATA_PATH = f'{DATA_ROOT}/patient_sequences.parquet'\n",
    "SAMPLE_DATA_PATH = f'{DATA_ROOT}/CEHR-BERT_sample_patient_sequence.parquet'\n",
    "FREQ_DF_PATH = f'{DATA_ROOT}/patient_feature_freq.csv'\n",
    "FREQ_MATRIX_PATH = f'{DATA_ROOT}/patient_freq_matrix.npz'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'NVIDIA GeForce GTX 1650 Ti'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class config:\n",
    "    seed = 23\n",
    "    data_dir = DATA_ROOT\n",
    "    test_size = 0.2\n",
    "    max_len = 500\n",
    "    batch_size = 16\n",
    "    num_workers = 2\n",
    "    vocab_size = None\n",
    "    embedding_size = 128\n",
    "    time_embeddings_size = 16\n",
    "    max_seq_length = 512\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "def seed_all(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # pl.seed_everything(seed)\n",
    "\n",
    "seed_all(config.seed)\n",
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T18:27:11.605126500Z",
     "start_time": "2024-01-22T18:27:11.597211400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 patient_id  num_visits  label  \\\n0      be7990af-3829-5df0-b552-c397a71d46fe           3      0   \n1      877d281b-676b-53ab-9911-1e4677989f6f           1      0   \n2      65ae1ba2-dede-53a4-80be-3d0666b27e87           1      0   \n3      aa1446f6-dbc4-5734-9645-a1e01a7ba6f0           1      0   \n4      b3c303cc-df8c-5789-80f0-83f1c319b813           1      1   \n...                                     ...         ...    ...   \n90273  88ae054e-0173-5049-b067-a67bad1aeee9           1      0   \n90274  3b6ec88d-59a8-5833-8977-48e8b58211b1           1      0   \n90275  b883470b-664e-5f0e-b38c-717cd5b07b84           1      0   \n90277  c946654b-2765-5dc1-8cd4-9865d3c84d30           2      0   \n90278  fd4c2513-8fb6-56f3-b142-009e3d0f520f           1      0   \n\n       death_after_start  death_after_end  length  token_length  new_start  \\\n0                    NaN              NaN     217           225        NaN   \n1                    NaN              NaN      18            20        NaN   \n2                    NaN              NaN      40            42        NaN   \n3                    NaN              NaN      18            20        NaN   \n4                   22.0             17.0      81            83        NaN   \n...                  ...              ...     ...           ...        ...   \n90273                NaN              NaN      36            38        NaN   \n90274                NaN              NaN      17            19        NaN   \n90275                3.0              0.0     152           154        NaN   \n90277                NaN              NaN      46            51        NaN   \n90278                NaN              NaN      76            78        NaN   \n\n                                event_tokens_untruncated  \\\n0      [VS, 4443, 00338004304, 00006473900, 000935211...   \n1      [VS, 741, 00182864389, 00904585461, 0070345020...   \n2      [VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...   \n3      [VS, 0689, 33332000801, 00056017075, 655970103...   \n4      [VS, 7935, 00338067104, 00054855324, 009045165...   \n...                                                  ...   \n90273  [VS, 7931, 00075062041, 00023050601, 005363381...   \n90274  [VS, 00338067104, 51079045620, 66553000401, 00...   \n90275  [VS, 5503, 00338004904, 00006494300, 001828447...   \n90277  [VS, 51079088120, 51079088120, 68084025401, 00...   \n90278  [VS, 8151, 0077, 00574705050, 00904516561, 003...   \n\n                                            event_tokens  \\\n0      [VS, 4443, 00338004304, 00006473900, 000935211...   \n1      [VS, 741, 00182864389, 00904585461, 0070345020...   \n2      [VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...   \n3      [VS, 0689, 33332000801, 00056017075, 655970103...   \n4      [VS, 7935, 00338067104, 00054855324, 009045165...   \n...                                                  ...   \n90273  [VS, 7931, 00075062041, 00023050601, 005363381...   \n90274  [VS, 00338067104, 51079045620, 66553000401, 00...   \n90275  [VS, 5503, 00338004904, 00006494300, 001828447...   \n90277  [VS, 51079088120, 51079088120, 68084025401, 00...   \n90278  [VS, 8151, 0077, 00574705050, 00904516561, 003...   \n\n                                              age_tokens  \\\n0      [66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 6...   \n1      [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 3...   \n2      [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2...   \n3      [77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 7...   \n4      [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 6...   \n...                                                  ...   \n90273  [32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 3...   \n90274  [68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 6...   \n90275  [81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 8...   \n90277  [45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 4...   \n90278  [68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 6...   \n\n                                             time_tokens  \\\n0      [8000, 8000, 8000, 8000, 8000, 8000, 8000, 800...   \n1      [5085, 5085, 5085, 5085, 5085, 5085, 5085, 508...   \n2      [8787, 8787, 8787, 8787, 8787, 8787, 8787, 878...   \n3      [4853, 4853, 4853, 4853, 4853, 4853, 4853, 485...   \n4      [6037, 6037, 6037, 6037, 6037, 6037, 6037, 603...   \n...                                                  ...   \n90273  [8788, 8788, 8788, 8788, 8788, 8788, 8788, 878...   \n90274  [5353, 5353, 5353, 5353, 5353, 5353, 5353, 535...   \n90275  [7450, 7450, 7450, 7450, 7450, 7450, 7450, 745...   \n90277  [4850, 4850, 4850, 4850, 4850, 4850, 4850, 485...   \n90278  [8480, 8480, 8480, 8480, 8480, 8480, 8480, 848...   \n\n                                            visit_tokens  \\\n0      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n1      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n2      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n3      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n4      [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n...                                                  ...   \n90273  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n90274  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n90275  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n90277  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n90278  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n\n                                         position_tokens  \n0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n...                                                  ...  \n90273  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n90274  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n90275  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n90277  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n90278  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n\n[173671 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>num_visits</th>\n      <th>label</th>\n      <th>death_after_start</th>\n      <th>death_after_end</th>\n      <th>length</th>\n      <th>token_length</th>\n      <th>new_start</th>\n      <th>event_tokens_untruncated</th>\n      <th>event_tokens</th>\n      <th>age_tokens</th>\n      <th>time_tokens</th>\n      <th>visit_tokens</th>\n      <th>position_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>be7990af-3829-5df0-b552-c397a71d46fe</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>217</td>\n      <td>225</td>\n      <td>NaN</td>\n      <td>[VS, 4443, 00338004304, 00006473900, 000935211...</td>\n      <td>[VS, 4443, 00338004304, 00006473900, 000935211...</td>\n      <td>[66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 6...</td>\n      <td>[8000, 8000, 8000, 8000, 8000, 8000, 8000, 800...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>877d281b-676b-53ab-9911-1e4677989f6f</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>[VS, 741, 00182864389, 00904585461, 0070345020...</td>\n      <td>[VS, 741, 00182864389, 00904585461, 0070345020...</td>\n      <td>[37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 3...</td>\n      <td>[5085, 5085, 5085, 5085, 5085, 5085, 5085, 508...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65ae1ba2-dede-53a4-80be-3d0666b27e87</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n      <td>42</td>\n      <td>NaN</td>\n      <td>[VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...</td>\n      <td>[VS, 51248_2, 51736_2, 51244_3, 51222_4, 51737...</td>\n      <td>[24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2...</td>\n      <td>[8787, 8787, 8787, 8787, 8787, 8787, 8787, 878...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aa1446f6-dbc4-5734-9645-a1e01a7ba6f0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>[VS, 0689, 33332000801, 00056017075, 655970103...</td>\n      <td>[VS, 0689, 33332000801, 00056017075, 655970103...</td>\n      <td>[77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 7...</td>\n      <td>[4853, 4853, 4853, 4853, 4853, 4853, 4853, 485...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b3c303cc-df8c-5789-80f0-83f1c319b813</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>17.0</td>\n      <td>81</td>\n      <td>83</td>\n      <td>NaN</td>\n      <td>[VS, 7935, 00338067104, 00054855324, 009045165...</td>\n      <td>[VS, 7935, 00338067104, 00054855324, 009045165...</td>\n      <td>[62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 6...</td>\n      <td>[6037, 6037, 6037, 6037, 6037, 6037, 6037, 603...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90273</th>\n      <td>88ae054e-0173-5049-b067-a67bad1aeee9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>36</td>\n      <td>38</td>\n      <td>NaN</td>\n      <td>[VS, 7931, 00075062041, 00023050601, 005363381...</td>\n      <td>[VS, 7931, 00075062041, 00023050601, 005363381...</td>\n      <td>[32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 3...</td>\n      <td>[8788, 8788, 8788, 8788, 8788, 8788, 8788, 878...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>90274</th>\n      <td>3b6ec88d-59a8-5833-8977-48e8b58211b1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17</td>\n      <td>19</td>\n      <td>NaN</td>\n      <td>[VS, 00338067104, 51079045620, 66553000401, 00...</td>\n      <td>[VS, 00338067104, 51079045620, 66553000401, 00...</td>\n      <td>[68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 6...</td>\n      <td>[5353, 5353, 5353, 5353, 5353, 5353, 5353, 535...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>90275</th>\n      <td>b883470b-664e-5f0e-b38c-717cd5b07b84</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>152</td>\n      <td>154</td>\n      <td>NaN</td>\n      <td>[VS, 5503, 00338004904, 00006494300, 001828447...</td>\n      <td>[VS, 5503, 00338004904, 00006494300, 001828447...</td>\n      <td>[81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 8...</td>\n      <td>[7450, 7450, 7450, 7450, 7450, 7450, 7450, 745...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>90277</th>\n      <td>c946654b-2765-5dc1-8cd4-9865d3c84d30</td>\n      <td>2</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>46</td>\n      <td>51</td>\n      <td>NaN</td>\n      <td>[VS, 51079088120, 51079088120, 68084025401, 00...</td>\n      <td>[VS, 51079088120, 51079088120, 68084025401, 00...</td>\n      <td>[45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 4...</td>\n      <td>[4850, 4850, 4850, 4850, 4850, 4850, 4850, 485...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>90278</th>\n      <td>fd4c2513-8fb6-56f3-b142-009e3d0f520f</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>76</td>\n      <td>78</td>\n      <td>NaN</td>\n      <td>[VS, 8151, 0077, 00574705050, 00904516561, 003...</td>\n      <td>[VS, 8151, 0077, 00574705050, 00904516561, 003...</td>\n      <td>[68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 6...</td>\n      <td>[8480, 8480, 8480, 8480, 8480, 8480, 8480, 848...</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>173671 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_parquet(DATA_PATH)\n",
    "data.rename(columns={'event_tokens': 'event_tokens_untruncated', 'event_tokens_updated': 'event_tokens'}, inplace=True)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T18:27:15.464907500Z",
     "start_time": "2024-01-22T18:27:15.380103400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# data['position_tokens'] = data['position_tokens'].apply(lambda x: np.zeros_like(x))\n",
    "data['label'] = ((data['death_after_end'] > 0) & (data['death_after_end'] < 365)).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T18:27:18.295597700Z",
     "start_time": "2024-01-22T18:27:18.278211300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<models.cehr_bert.tokenizer.ConceptTokenizer at 0x26cf3fdf650>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = ConceptTokenizer(data_dir=config.data_dir)\n",
    "tokenizer.fit_on_vocab()\n",
    "config.vocab_size = tokenizer.get_vocab_size()\n",
    "tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T18:27:20.615738400Z",
     "start_time": "2024-01-22T18:27:20.483776800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "            data,\n",
    "            test_size=config.test_size,\n",
    "            random_state=config.seed,\n",
    "            stratify=data['label']\n",
    "        )\n",
    "\n",
    "train_dataset = FinetuneDataset(\n",
    "        data=train_data,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=config.max_len,\n",
    ")\n",
    "\n",
    "test_dataset = FinetuneDataset(\n",
    "        data=test_data,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=config.max_len,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T18:28:03.597214300Z",
     "start_time": "2024-01-22T18:28:03.371888500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class BiLSTMModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_size, num_layers, output_size, dropout_rate=0.5):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "\n",
    "        self.embeddings = Embeddings(\n",
    "            vocab_size=config.vocab_size,\n",
    "            embedding_size=config.embedding_size,\n",
    "            time_embedding_size=config.time_embeddings_size,\n",
    "            max_len=config.max_seq_length)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size * 2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(hidden_size * 2, output_size)  # Multiply by 2 for bidirectional\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.embeddings(*inputs)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = lstm_out[:, -1, :]\n",
    "        output = self.batch_norm(output)\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T18:28:06.350636400Z",
     "start_time": "2024-01-22T18:28:06.341414300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Set hyperparameters for Bi-LSTM model\n",
    "input_size = config.embedding_size              # embedding_dim\n",
    "hidden_size = config.embedding_size // 2\n",
    "num_layers = 5                                  # Number of LSTM layers\n",
    "output_size = 1                                 # Binary classification, so output size is 1\n",
    "dropout_rate = 0.5                              # Dropout rate for regularization\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 0.005"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T18:28:06.617891700Z",
     "start_time": "2024-01-22T18:28:06.595652300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 8684/8684 [09:59<00:00, 14.49 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10  |  Average Train Loss: 0.30950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 8684/8684 [12:10<00:00, 11.90 batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10  |  Average Train Loss: 0.27158\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m      7\u001B[0m     train_total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m----> 9\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch_no, batch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28menumerate\u001B[39m(train_loader),\n\u001B[0;32m     10\u001B[0m                                            total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m batch\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     12\u001B[0m         labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(config\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     13\u001B[0m         inputs \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconcept_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(config\u001B[38;5;241m.\u001B[39mdevice),\\\n\u001B[0;32m     14\u001B[0m                  batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime_stamps\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(config\u001B[38;5;241m.\u001B[39mdevice),\\\n\u001B[0;32m     15\u001B[0m                  batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mages\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(config\u001B[38;5;241m.\u001B[39mdevice),\\\n\u001B[0;32m     16\u001B[0m                  batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvisit_orders\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(config\u001B[38;5;241m.\u001B[39mdevice),\\\n\u001B[0;32m     17\u001B[0m                  batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvisit_segments\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(config\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[1;32m~\\.conda\\envs\\light\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_iterator()\n",
      "File \u001B[1;32m~\\.conda\\envs\\light\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _MultiProcessingDataLoaderIter(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\light\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1035\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1042\u001B[0m w\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32m~\\.conda\\envs\\light\\Lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Popen(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\light\\Lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _default_context\u001B[38;5;241m.\u001B[39mget_context()\u001B[38;5;241m.\u001B[39mProcess\u001B[38;5;241m.\u001B[39m_Popen(process_obj)\n",
      "File \u001B[1;32m~\\.conda\\envs\\light\\Lib\\multiprocessing\\context.py:336\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    334\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    335\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 336\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Popen(process_obj)\n",
      "File \u001B[1;32m~\\.conda\\envs\\light\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     93\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 94\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(process_obj, to_child)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     96\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\light\\Lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     ForkingPickler(file, protocol)\u001B[38;5;241m.\u001B[39mdump(obj)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = BiLSTMModel(input_size, hidden_size, num_layers, output_size, dropout_rate).to(config.device)\n",
    "loss_fcn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_total_loss = 0.0\n",
    "\n",
    "    for batch_no, batch in tqdm(enumerate(train_loader),\n",
    "                                           total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit=' batch'):\n",
    "\n",
    "        labels = batch['labels'].view(-1, 1).to(config.device)\n",
    "        inputs = batch['concept_ids'].to(config.device),\\\n",
    "                 batch['time_stamps'].to(config.device),\\\n",
    "                 batch['ages'].to(config.device),\\\n",
    "                 batch['visit_orders'].to(config.device),\\\n",
    "                 batch['visit_segments'].to(config.device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fcn(outputs, labels.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_total_loss += loss.item()\n",
    "        # print(f'Batch Loss: {loss.item():.4f}', end='\\r')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}  |  Average Train Loss: {train_total_loss/len(train_loader):.5f}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T18:55:16.578878100Z",
     "start_time": "2024-01-22T18:28:08.353683400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test check in loop\n",
    "# jupyter + cluster setup\n",
    "# reevaluate xgboost with new label and send it github"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
